{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "be20361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import initialize_agent, Tool\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "import operator\n",
    "# from langchain.prompts import PromptTemplate\n",
    "import requests\n",
    "from github import Github\n",
    "import os\n",
    "import getpass\n",
    "from bandit.core import manager, config\n",
    "from azure.identity import ManagedIdentityCredential\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7db4e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Config ===\n",
    "REPO_NAME = \"greenqloud/cloud-backup-service\"\n",
    "PULL_REQUEST_NUMBER = 1853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8c1134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === LangChain LLM ===\n",
    "# #  getting the required ssl certificates\n",
    "# pem_path = \"/opt/homebrew/etc/openssl@3/cert.pem\"\n",
    "# # Ensure the environment variables are set before making the API call\n",
    "# os.environ['REQUESTS_CA_BUNDLE'] = pem_path\n",
    "# os.environ['SSL_CERT_FILE'] = pem_path\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model_name      = \"gpt-4o-mini\",\n",
    "#                  openai_api_base = config.OPENAI_ENDPOINT,\n",
    "#                  openai_api_key  = config.OPENAI_API_KEY,\n",
    "#                  model_kwargs    = {'user': getpass.getuser() },\n",
    "#                  temperature = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45749c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pr_diff_and_metadata(repo_name=REPO_NAME, pr_number=PULL_REQUEST_NUMBER, github_token=config.GITHUB_TOKEN):\n",
    "    \"\"\"\n",
    "    Fetch pull request metadata and diff from GitHub.\n",
    "\n",
    "    Args:\n",
    "        repo_name (str): The full repository name (e.g., \"owner/repo\").\n",
    "        pr_number (int): The pull request number.\n",
    "        github_token (str): GitHub personal access token.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "    \"\"\"\n",
    "    g = Github(github_token)\n",
    "    repo = g.get_repo(repo_name)\n",
    "    pr = repo.get_pull(pr_number)\n",
    "    pr_title = pr.title\n",
    "    pr_body = pr.body\n",
    "    diff_response = requests.get(\n",
    "        f\"https://api.github.com/repos/{repo_name}/pulls/{pr_number}\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"token {github_token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "        }\n",
    "    )\n",
    "    diff_text = diff_response.text\n",
    "    return diff_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7f4cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tool 1: GitHub PR Fetcher ===\n",
    "def fetch_pr_diff_and_metadata(repo_name=REPO_NAME, pr_number=PULL_REQUEST_NUMBER, github_token=config.GITHUB_TOKEN):\n",
    "    \"\"\"\n",
    "    Fetch pull request metadata and diff from GitHub.\n",
    "\n",
    "    Args:\n",
    "        repo_name (str): The full repository name (e.g., \"owner/repo\").\n",
    "        pr_number (int): The pull request number.\n",
    "        github_token (str): GitHub personal access token.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "    \"\"\"\n",
    "    g = Github(github_token)\n",
    "    repo = g.get_repo(repo_name)\n",
    "    pr = repo.get_pull(pr_number)\n",
    "    pr_title = pr.title\n",
    "    pr_body = pr.body\n",
    "    diff_response = requests.get(\n",
    "        f\"https://api.github.com/repos/{repo_name}/pulls/{pr_number}\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"token {github_token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "        }\n",
    "    )\n",
    "    diff_text = diff_response.text\n",
    "    return diff_text\n",
    "class prrepo(BaseModel):\n",
    "    repo_name: str = Field(description=\"Repo to execute\")\n",
    "    pr_number: int = Field(description=\"PR number to execute\")\n",
    "@tool(args_schema = prrepo)\n",
    "def fetchprdiff(repo_name: str, pr_number: int) -> str:\n",
    "  \"\"\"Returns the result of diff text in a PR\"\"\"\n",
    "  return fetch_pr_diff_and_metadata(repo_name, pr_number, github_token=config.GITHUB_TOKEN)\n",
    "\n",
    "\n",
    "# === Tool 1: GitHub File Fetcher ===\n",
    "def get_file_context(filename, ref=\"master\"):\n",
    "    g = Github(config.GITHUB_TOKEN)\n",
    "    repo = g.get_repo(REPO_NAME)\n",
    "    try:\n",
    "        contents = repo.get_contents(filename, ref=ref)\n",
    "        return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching file {filename}: {e}\"\n",
    "# Tool for langrgaph\n",
    "\n",
    "class filecontent(BaseModel):\n",
    "    filename: str = Field(description=\"Get full contents of file\")\n",
    "@tool(args_schema = filecontent)\n",
    "def file_fetch_tool(filename: str, ref: str = \"master\") -> str:\n",
    "   \"\"\"\n",
    "    Fetch full content of a given file from the repo for additional context.\n",
    "    \"\"\"\n",
    "   return get_file_context(filename, ref=\"master\")\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 2: Prometheus metrics fetcher ===\n",
    "def get_prometheus_metrics(prometheus_url):\n",
    "    try:\n",
    "        credential = ManagedIdentityCredential(client_id=os.getenv(\"prometheus_client_id\"))\n",
    "        token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\"\n",
    "        }\n",
    "        response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data.get('status') == 'success':\n",
    "            return data.get('data', [])\n",
    "        else:\n",
    "            print(f\"Error from Prometheus API: {data}\")\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request failed: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "# Tool for LangGraph\n",
    "class prometheusmetricsurl(BaseModel):\n",
    "    prometheus_url: str = Field(description=\"Get full contents of file\")\n",
    "@tool(args_schema = prometheusmetricsurl)\n",
    "def prometheus_metrics_fetch_tool(prometheus_url: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all the prometheus metrics from azure monitor workspace to get context for observability.\n",
    "    \"\"\"\n",
    "    return get_prometheus_metrics(prometheus_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "#place holder to add - copy from saw\n",
    "\n",
    "# === Tool 4: Bandit Code Security checker ===\n",
    "def check_code_security(file_path):\n",
    "    \"\"\"\n",
    "    Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "    :param file_path: Path to the Python file to analyze\n",
    "    :return: Bandit report as a string\n",
    "    \"\"\"\n",
    "    # Load Bandit configuration\n",
    "    bandit_config = config.BanditConfig()\n",
    "\n",
    "    # Initialize Bandit manager\n",
    "    bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "    # Run Bandit on the specified file\n",
    "    bandit_manager.discover_files([file_path])\n",
    "    bandit_manager.run_tests()\n",
    "\n",
    "    # Generate and return the report\n",
    "    issues = bandit_manager.get_issue_list()\n",
    "    if not issues:\n",
    "        return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "    # If no high-level issues, check for lower-level issues\n",
    "    lower_level_issues = []\n",
    "    for issue in issues:\n",
    "        if issue.severity.lower() in ['low', 'medium']:\n",
    "            lower_level_issues.append(str(issue))\n",
    "\n",
    "    if lower_level_issues:\n",
    "        return \"\\n\".join(lower_level_issues)\n",
    "    else:\n",
    "        return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# Tool wrapper for LangChain\n",
    "class banditsecurity(BaseModel):\n",
    "    file_path: str = Field(description=\"Get path of file to execute\")\n",
    "@tool(args_schema = banditsecurity)\n",
    "def bandit_security_checker_tool(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Check security of a python code using bandit library.\n",
    "    \"\"\"\n",
    "    return check_code_security(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d508e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Tool 1: GitHub PR Fetcher ===\n",
    "# def fetch_pr_diff_and_metadata(repo_name, pr_number, github_token):\n",
    "#     \"\"\"\n",
    "#     Fetch pull request metadata and diff from GitHub.\n",
    "\n",
    "#     Args:\n",
    "#         repo_name (str): The full repository name (e.g., \"owner/repo\").\n",
    "#         pr_number (int): The pull request number.\n",
    "#         github_token (str): GitHub personal access token.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "#     \"\"\"\n",
    "#     g = Github(github_token)\n",
    "#     repo = g.get_repo(repo_name)\n",
    "#     pr = repo.get_pull(pr_number)\n",
    "#     pr_title = pr.title\n",
    "#     pr_body = pr.body\n",
    "#     diff_response = requests.get(\n",
    "#         f\"https://api.github.com/repos/{repo_name}/pulls/{pr_number}\",\n",
    "#         headers={\n",
    "#             \"Authorization\": f\"token {github_token}\",\n",
    "#             \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "#         }\n",
    "#     )\n",
    "#     diff_text = diff_response.text\n",
    "#     return diff_text\n",
    "# # Tool for langrgaph\n",
    "# @tool\n",
    "# def pr_diff_and_metadata_fetch_tool(repo_name: str, pr_number: int, github_token: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Fetch pull request metadata and diff from GitHub.\n",
    "#     Returns a dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "#     \"\"\"\n",
    "#     pr, diff_text = fetch_pr_diff_and_metadata(repo_name, pr_number, github_token)\n",
    "#     return {\n",
    "#         \"pr_title\": pr.title,\n",
    "#         \"pr_body\": pr.body,\n",
    "#         \"diff_text\": diff_text\n",
    "#     }\n",
    "\n",
    "# # === Tool 1: GitHub File Fetcher ===\n",
    "# def get_file_context(filename, ref=\"master\"):\n",
    "#     g = Github(config.GITHUB_TOKEN)\n",
    "#     repo = g.get_repo(REPO_NAME)\n",
    "#     try:\n",
    "#         contents = repo.get_contents(filename, ref=ref)\n",
    "#         return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "#     except Exception as e:\n",
    "#         return f\"Error fetching file {filename}: {e}\"\n",
    "# # Tool for langrgaph\n",
    "# @tool\n",
    "# def file_fetch_tool(filename: str, ref: str = \"master\") -> str:\n",
    "#     \"\"\"\n",
    "#     Fetch full content of a given file from the repo for additional context.\n",
    "#     \"\"\"\n",
    "#     return get_file_context(filename, ref=\"master\")\n",
    "\n",
    "\n",
    "# # === Tool 2: Prometheus metrics fetcher ===\n",
    "# def get_prometheus_metrics(prometheus_url):\n",
    "#     try:\n",
    "#         credential = ManagedIdentityCredential(client_id=os.getenv(\"prometheus_client_id\"))\n",
    "#         token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "#         headers = {\n",
    "#             \"Authorization\": f\"Bearer {token}\"\n",
    "#         }\n",
    "#         response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "#         if data.get('status') == 'success':\n",
    "#             return data.get('data', [])\n",
    "#         else:\n",
    "#             print(f\"Error from Prometheus API: {data}\")\n",
    "#             return []\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"HTTP request failed: {e}\")\n",
    "#         return []\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         return []\n",
    "# # Tool for LangGraph\n",
    "# @tool\n",
    "# def prometheus_metrics_fetch_tool(prometheus_url: str) -> list:\n",
    "#     \"\"\"\n",
    "#     Fetch all the prometheus metrics from azure monitor workspace to get context for observability.\n",
    "#     \"\"\"\n",
    "#     return get_prometheus_metrics(prometheus_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "# #place holder to add - copy from saw\n",
    "\n",
    "# # === Tool 4: Bandit Code Security checker ===\n",
    "# def check_code_security(file_path):\n",
    "#     \"\"\"\n",
    "#     Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "#     :param file_path: Path to the Python file to analyze\n",
    "#     :return: Bandit report as a string\n",
    "#     \"\"\"\n",
    "#     # Load Bandit configuration\n",
    "#     bandit_config = config.BanditConfig()\n",
    "\n",
    "#     # Initialize Bandit manager\n",
    "#     bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "#     # Run Bandit on the specified file\n",
    "#     bandit_manager.discover_files([file_path])\n",
    "#     bandit_manager.run_tests()\n",
    "\n",
    "#     # Generate and return the report\n",
    "#     issues = bandit_manager.get_issue_list()\n",
    "#     if not issues:\n",
    "#         return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "#     # If no high-level issues, check for lower-level issues\n",
    "#     lower_level_issues = []\n",
    "#     for issue in issues:\n",
    "#         if issue.severity.lower() in ['low', 'medium']:\n",
    "#             lower_level_issues.append(str(issue))\n",
    "\n",
    "#     if lower_level_issues:\n",
    "#         return \"\\n\".join(lower_level_issues)\n",
    "#     else:\n",
    "#         return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# # Tool wrapper for LangChain\n",
    "# @tool\n",
    "# def bandit_security_checker_tool(file_path: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Check security of a python code using bandit library.\n",
    "#     \"\"\"\n",
    "#     return check_code_security(file_path)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e93f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Tool 1: GitHub File Fetcher ===\n",
    "# def get_file_context(filename, ref=\"master\"):\n",
    "#     g = Github(config.GITHUB_TOKEN)\n",
    "#     repo = g.get_repo(REPO_NAME)\n",
    "#     try:\n",
    "#         contents = repo.get_contents(filename, ref=ref)\n",
    "#         return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "#     except Exception as e:\n",
    "#         return f\"Error fetching file {filename}: {e}\"\n",
    "# # Tool wrapper for LangChain\n",
    "# file_fetch_tool = Tool(\n",
    "#     name=\"FileFetcher\",\n",
    "#     func=lambda filename: get_file_context(filename, ref=\"master\"),\n",
    "#     description=\"Fetch full content of a given file from the repo for additional context\"\n",
    "# )\n",
    "\n",
    "# # === Tool 2: Prometheus metrics fetcher ===\n",
    "# def get_prometheus_metrics(prometheus_url):\n",
    "#     try:\n",
    "#         credential = ManagedIdentityCredential(client_id=os.getenv(\"prometheus_client_id\"))\n",
    "#         token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "#         headers = {\n",
    "#             \"Authorization\": f\"Bearer {token}\"\n",
    "#         }\n",
    "#         response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "#         if data.get('status') == 'success':\n",
    "#             return data.get('data', [])\n",
    "#         else:\n",
    "#             print(f\"Error from Prometheus API: {data}\")\n",
    "#             return []\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"HTTP request failed: {e}\")\n",
    "#         return []\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         return []\n",
    "# # Tool wrapper for LangChain\n",
    "# prometheus_metrics_fetch_tool = Tool(\n",
    "#     name=\"PrometheusMetricsFetcher\",\n",
    "#     func=lambda prometheus_url: get_prometheus_metrics(prometheus_url),\n",
    "#     description=\"Fetch all the prometheus metrics from azure monitor workspace to get context for observability\"\n",
    "# )\n",
    "# # === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "# #place holder to add - copy from saw\n",
    "\n",
    "# # === Tool 4: Bandit Code Security checker ===\n",
    "# def check_code_security(file_path):\n",
    "#     \"\"\"\n",
    "#     Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "#     :param file_path: Path to the Python file to analyze\n",
    "#     :return: Bandit report as a string\n",
    "#     \"\"\"\n",
    "#     # Load Bandit configuration\n",
    "#     bandit_config = config.BanditConfig()\n",
    "\n",
    "#     # Initialize Bandit manager\n",
    "#     bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "#     # Run Bandit on the specified file\n",
    "#     bandit_manager.discover_files([file_path])\n",
    "#     bandit_manager.run_tests()\n",
    "\n",
    "#     # Generate and return the report\n",
    "#     issues = bandit_manager.get_issue_list()\n",
    "#     if not issues:\n",
    "#         return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "#     # If no high-level issues, check for lower-level issues\n",
    "#     lower_level_issues = []\n",
    "#     for issue in issues:\n",
    "#         if issue.severity.lower() in ['low', 'medium']:\n",
    "#             lower_level_issues.append(str(issue))\n",
    "\n",
    "#     if lower_level_issues:\n",
    "#         return \"\\n\".join(lower_level_issues)\n",
    "#     else:\n",
    "#         return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# # Tool wrapper for LangChain\n",
    "# bandit_security_checker_tool = Tool(\n",
    "#     name=\"BanditSecurityChecker\",\n",
    "#     func=lambda file_path: check_code_security(file_path),\n",
    "#     description=\"Check security of a python code using bandit library\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f585130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "801b8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = Github(config.GITHUB_TOKEN)\n",
    "# repo = g.get_repo(REPO_NAME)\n",
    "# pr = repo.get_pull(PULL_REQUEST_NUMBER)\n",
    "# pr_title = pr.title\n",
    "# pr_body = pr.body\n",
    "# diff_response = requests.get(\n",
    "#     f\"https://api.github.com/repos/{REPO_NAME}/pulls/{PULL_REQUEST_NUMBER}\",\n",
    "#     headers={\n",
    "#         \"Authorization\": f\"token {config.GITHUB_TOKEN}\",\n",
    "#         \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "#     }\n",
    "# )\n",
    "# diff_text = diff_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "846a1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Step 2: Build Agent Prompt ===\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"diff\", \"title\", \"description\"],\n",
    "#     template=\"\"\"\n",
    "# You are a senior AI engineer agent. you would wear multiple hats in the fields of observability and security\n",
    "# TASK:\n",
    "# Analyze the given pull request diff for potential observability and security issues.\n",
    "# Use a checklist for each area:\n",
    "# For observability:\n",
    "# - Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?\n",
    "# - Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?\n",
    "# - Are there CorrelationIDs established in logs to derive error lineage across various components?\n",
    "# - Can the feature/service support changing log levels for troubleshooting purposes?\n",
    "# - Are there critical log lines that we need to get alerted upon?\n",
    "# For Security \n",
    "# - All sensitive log lines are masked appropriately?\n",
    "# - Are all secrets encrypted at rest and in transit?\n",
    "# - Are all data encrypted at rest and in transit?\n",
    "# - Are we using distroless/mariner base image/s?\n",
    "# If the diff is unclear, use the FileFetcher tool to retrieve extra context of the file.\n",
    "# Pull Request Title:\n",
    "# {title}\n",
    "# Pull Request Description:\n",
    "# {description}\n",
    "# Diff:\n",
    "# {diff}\n",
    "# If the file has import from custom modules use the FileFetcher tool to retreive the file\n",
    "# Tell me if you fetched files for additional context\n",
    "# Begin step-by-step reasoning.\n",
    "# First, summarize what the change is doing.\n",
    "# Then, identify observability gaps and risky areas.\n",
    "# Finally, provide a observability and security risk report.\n",
    "# \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8dcffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Step 3: Initialize LangChain Agent ===\n",
    "# agent = initialize_agent(\n",
    "#     tools=[file_fetch_tool],\n",
    "#     agent=\"chat-conversational-react-description\",\n",
    "#     llm=config.llm,\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a133ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Step 4: Run the Agent ===\n",
    "# input_prompt = prompt_template.format(\n",
    "#     diff=diff_text,\n",
    "#     title=pr.title,\n",
    "#     description=pr.body\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b4f90a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent.run({\"input\": input_prompt, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dec9ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Step 5: Output the result ===\n",
    "# print(\"\\n=== Security Agent Report ===\\n\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "206fa2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent state\n",
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a3e0cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRRAgent:\n",
    "  # initialising the object\n",
    "  def __init__(self, model, tools, system_prompt = \"\"):\n",
    "    self.system_prompt = system_prompt\n",
    "\n",
    "    # initialising graph with a state \n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    # adding nodes \n",
    "    graph.add_node(\"llm\", self.call_llm)\n",
    "    graph.add_node(\"function\", self.execute_function)\n",
    "    graph.add_conditional_edges(\n",
    "      \"llm\",\n",
    "      self.exists_function_calling,\n",
    "      {True: \"function\", False: END}\n",
    "    )\n",
    "    graph.add_edge(\"function\", \"llm\")\n",
    "\n",
    "    # setting starting point\n",
    "    graph.set_entry_point(\"llm\")\n",
    "\n",
    "    self.graph = graph.compile()\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "    self.model = model.bind_tools(tools)\n",
    "\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    try:\n",
    "      display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    except Exception:\n",
    "      # This requires some extra dependencies and is optional\n",
    "      pass\n",
    "\n",
    "  def call_llm(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    # adding system prompt if it's defined\n",
    "    if self.system_prompt:\n",
    "        messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "\n",
    "    # calling LLM\n",
    "    message = self.model.invoke(messages)\n",
    "\n",
    "    return {'messages': [message]}\n",
    "  \n",
    "  def execute_function(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    results = []\n",
    "    for tool in tool_calls:\n",
    "      # checking whether tool name is correct\n",
    "      if not tool['name'] in self.tools:\n",
    "        # returning error to the agent \n",
    "        result = \"Error: There's no such tool, please, try again\" \n",
    "      else:\n",
    "        # getting result from the tool\n",
    "        result = self.tools[tool['name']].invoke(tool['args'])\n",
    "\n",
    "      results.append(\n",
    "        ToolMessage(\n",
    "          tool_call_id=tool['id'], \n",
    "          name=tool['name'], \n",
    "          content=str(result)\n",
    "        )\n",
    "    )\n",
    "    return {'messages': results}\n",
    "  \n",
    "  def exists_function_calling(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ff8bd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Request Title:\n",
    "# {title}\n",
    "# Pull Request Description:\n",
    "# {description}\n",
    "# Diff:\n",
    "# {diff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd9b9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a senior AI engineer agent. you would wear multiple hats in the fields of observability and security\n",
    "TASK:\n",
    "Analyze the given pull request diff for potential observability and security issues.\n",
    "Use fetchprdiff tool to fetch the diff on a pull request\n",
    "Use a checklist for each area:\n",
    "For observability:\n",
    "- Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?\n",
    "- Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?\n",
    "- Are there CorrelationIDs established in logs to derive error lineage across various components?\n",
    "- Can the feature/service support changing log levels for troubleshooting purposes?\n",
    "- Are there critical log lines that we need to get alerted upon?\n",
    "For Security \n",
    "- All sensitive log lines are masked appropriately?\n",
    "- Are all secrets encrypted at rest and in transit?\n",
    "- Are all data encrypted at rest and in transit?\n",
    "- Are we using distroless/mariner base image/s?\n",
    "If the diff is unclear, use the FileFetcher tool to retrieve extra context of the file.\n",
    "If the file has import from custom modules use the file_fetch_tool tool to retreive the file\n",
    "Tell me if you fetched files for additional context\n",
    "Begin step-by-step reasoning.\n",
    "First, summarize what the change is doing.\n",
    "Then, identify observability gaps and risky areas.\n",
    "Finally, provide a observability and security risk report.\n",
    "Structure your response in a markdown table with the following columns:\n",
    "| Area | Gap | Risk Level | Recommendation |\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "53b84345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage: Analyze the pull request 1853 from greenqloud/cloud-backup-service\n",
      "\n",
      "ToolMessage: diff --git a/api_service/server/database/database.go b/api_service/server/database/database.go\n",
      "index af1e3b45d..44c0f5f7f 100644\n",
      "--- a/api_service/server/database/database.go\n",
      "+++ b/api_service/server/database/database.go\n",
      "@@ -35,6 +35,7 @@ const (\n",
      " \tDEFAULTLIMIT               = 100\n",
      " \t// MariaDBInReadOnlyModeError Expected substring for error incurred due to maria db being in read-only mode\n",
      " \tMariaDBInReadOnlyModeError = \"Error 1290: The MariaDB server is running with the --read-only\"\n",
      "+\tGSProcessingError          = \"GS is processing baseline backup\"\n",
      " )\n",
      " \n",
      " // The '_' and '%' are wildcards in a LIKE operated statement in SQL.\n",
      "@@ -174,15 +175,16 @@ func (sqlDb *SqlDatabase) CreateJobIfNotInProgress(jobType, fileSystemID, json s\n",
      " \tLIMIT 1`\n",
      " \t*/\n",
      " \tjobExists := false\n",
      "-\tvar row int\n",
      "+\n",
      "+\tvar job_type, errMsg string\n",
      " \texclusiveJobTypes := fmt.Sprintf(\"'%s','%s'\", util.RestoreJobType, util.DeleteQuarkObjectStoreType)\n",
      " \t// avoid duplicate sync jobs\n",
      " \tif jobType != util.UpdateDBJobType {\n",
      " \t\texclusiveJobTypes += fmt.Sprintf(\",'%s'\", util.UpdateDBJobType)\n",
      " \t}\n",
      "-\tqueryFmt := `SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = ? AND type NOT IN (` + exclusiveJobTypes + `)  \n",
      "+\tqueryFmt := `SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = ? AND type NOT IN (` + exclusiveJobTypes + `)  \n",
      "                  AND (status = '` + util.NEWSTATUS + `' OR status = '` + util.INPROGRESSSTATUS + `') LIMIT 1`\n",
      "-\terr := sqlDb.sql.QueryRow(queryFmt, fileSystemID).Scan(&row)\n",
      "+\terr := sqlDb.sql.QueryRow(queryFmt, fileSystemID).Scan(&job_type, &errMsg)\n",
      " \tif err != nil {\n",
      " \t\tif err != sql.ErrNoRows {\n",
      " \t\t\tsqlDb.GetTraceLog().Errorf(\"CreateJobIfNotInProgress(jobType=%s, fileSystemID=%s) failed: %v\", jobType, fileSystemID, err)\n",
      "@@ -193,6 +195,11 @@ func (sqlDb *SqlDatabase) CreateJobIfNotInProgress(jobType, fileSystemID, json s\n",
      " \t\tjobExists = true\n",
      " \t}\n",
      " \n",
      "+\tif jobExists && job_type == util.ScheduledBackupWithPolicyJobType && errMsg == GSProcessingError {\n",
      "+\t\tsqlDb.GetTraceLog().Errorf(\"jobExists in CreateJobIfNotInProgress(jobType=%s, fileSystemID=%s)\", jobType, fileSystemID)\n",
      "+\t\terrorMessage := \"Baseline backup is in progress. Please retry once baseline backup creation is completed.\"\n",
      "+\t\treturn 0, util.NewDuplicateEntryError(errorMessage)\n",
      "+\t}\n",
      " \tif jobExists {\n",
      " \t\tsqlDb.GetTraceLog().Errorf(\"jobExists in CreateJobIfNotInProgress(jobType=%s, fileSystemID=%s)\", jobType, fileSystemID)\n",
      " \t\terrorMessage := \"Cannot create a new job as another job is in progress for the given fileSystemID.\"\n",
      "diff --git a/api_service/server/database/miscellaneous_test.go b/api_service/server/database/miscellaneous_test.go\n",
      "index d70a5c6ef..0743d77ec 100644\n",
      "--- a/api_service/server/database/miscellaneous_test.go\n",
      "+++ b/api_service/server/database/miscellaneous_test.go\n",
      "@@ -181,8 +181,9 @@ func Test_CreateJobIfNotInProgress_DuplicateEntry(t *testing.T) {\n",
      " \n",
      " \tdefer resetSQLMock()\n",
      " \n",
      "-\tsqlMock.ExpectQuery(`SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "-                 AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).WillReturnRows(sqlmock.NewRows([]string{\"i\"}).AddRow(1))\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "+                 AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).\n",
      "+\t\tWillReturnRows(sqlmock.NewRows([]string{\"type\", \"error_message\"}).AddRow(util.AdhocBackupJobType, \"IN_PROGRESS_ERROR\"))\n",
      " \n",
      " \t_, createErr := dbTest.CreateJobIfNotInProgress(jobType, fileSystemID, json)\n",
      " \tassert.Equal(t, createErr, util.NewDuplicateEntryError(\"Cannot create a new job as another job is in progress for the given fileSystemID.\"))\n",
      "@@ -229,7 +230,7 @@ func Test_CreateJobIfNotInProgress_NoRowsSuccess_JobSuccess(t *testing.T) {\n",
      " \n",
      " \tdefer resetSQLMock()\n",
      " \n",
      "-\tsqlMock.ExpectQuery(`SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "                  AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).WillReturnError(sql.ErrNoRows)\n",
      " \n",
      " \tsqlMock.ExpectQuery(`INSERT INTO JOB_STATUS \\(type, status, error_message, message, file_system_uuid\\) VALUES \\(\\?, \\?, \\?, \\?, \\?\\)`).\n",
      "@@ -247,7 +248,7 @@ func Test_CreateJobIfNotInProgress_WhenJobTypeIsUpdateDB(t *testing.T) {\n",
      " \n",
      " \tdefer resetSQLMock()\n",
      " \n",
      "-\tsqlMock.ExpectQuery(`SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store'\\)\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store'\\)\n",
      "                  AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).WillReturnError(sql.ErrNoRows)\n",
      " \n",
      " \tsqlMock.ExpectQuery(`INSERT INTO JOB_STATUS \\(type, status, error_message, message, file_system_uuid\\) VALUES \\(\\?, \\?, \\?, \\?, \\?\\)`).\n",
      "@@ -258,6 +259,27 @@ func Test_CreateJobIfNotInProgress_WhenJobTypeIsUpdateDB(t *testing.T) {\n",
      " \tassert.EqualValues(t, id, 1)\n",
      " }\n",
      " \n",
      "+func Test_CreateJobIfNotInProgress_WhenJobExists_GSProcessingError(t *testing.T) {\n",
      "+\tjobType := util.ScheduledBackupWithPolicyJobType\n",
      "+\tfileSystemID := \"622EE7E2-AFDD-536D-A337-012345678923\"\n",
      "+\tjson := \"random data\"\n",
      "+\n",
      "+\tdefer resetSQLMock()\n",
      "+\n",
      "+\trows := sqlmock.NewRows([]string{\"type\", \"error_message\"}).\n",
      "+\t\tAddRow(util.ScheduledBackupWithPolicyJobType, GSProcessingError)\n",
      "+\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "+                 AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).\n",
      "+\t\tWithArgs(fileSystemID).\n",
      "+\t\tWillReturnRows(rows)\n",
      "+\n",
      "+\t_, createErr := dbTest.CreateJobIfNotInProgress(jobType, fileSystemID, json)\n",
      "+\n",
      "+\tassert.NotNil(t, createErr)\n",
      "+\tassert.Equal(t, \"Baseline backup is in progress. Please retry once baseline backup creation is completed.\", createErr.Error())\n",
      "+}\n",
      "+\n",
      " func Test_DeleteJob_NotFound(t *testing.T) {\n",
      " \tvar jobID uint64 = 1\n",
      " \n",
      "\n",
      "\n",
      "AIMessage: ### Summary of Changes\n",
      "The pull request introduces modifications to the `CreateJobIfNotInProgress` function in the `database.go` file. The changes include:\n",
      "1. Updating the SQL query to fetch both the job type and error message from the `JOB_STATUS` table instead of just checking for the existence of a job.\n",
      "2. Adding logic to handle a specific error case where a baseline backup is already in progress, returning a more informative error message.\n",
      "3. Corresponding updates to the unit tests to validate the new behavior, including a test for the new error handling.\n",
      "\n",
      "### Observability and Security Analysis\n",
      "\n",
      "#### Observability Gaps and Risks\n",
      "1. **Actionable Alerts**: The changes do not specify if there are actionable alerts for the new error conditions introduced. \n",
      "2. **Metrics for Monitoring**: There is no indication that metrics are being added to monitor the new error conditions or the job creation process.\n",
      "3. **Correlation IDs**: The code does not show any implementation of Correlation IDs in logs, which would help trace errors across components.\n",
      "4. **Log Levels**: There is no mention of the ability to change log levels for troubleshooting.\n",
      "5. **Critical Log Lines**: While there are error logs, it is unclear if there are critical log lines that need alerts.\n",
      "\n",
      "#### Security Gaps and Risks\n",
      "1. **Sensitive Log Lines**: The code does not indicate if sensitive information is being masked in logs.\n",
      "2. **Secrets Management**: There is no information regarding the encryption of secrets at rest and in transit.\n",
      "3. **Data Encryption**: The code does not specify if data is encrypted at rest and in transit.\n",
      "4. **Base Image**: There is no mention of using distroless or mariner base images, which are recommended for security.\n",
      "\n",
      "### Observability and Security Risk Report\n",
      "\n",
      "| Area       | Gap                                                                 | Risk Level | Recommendation                                                                                     |\n",
      "|------------|---------------------------------------------------------------------|------------|---------------------------------------------------------------------------------------------------|\n",
      "| Observability | No actionable alerts for new error conditions.                     | High       | Define and implement actionable alerts for the new error conditions introduced in the PR.        |\n",
      "| Observability | Lack of metrics for monitoring job creation and error handling.    | Medium     | Add metrics to monitor job creation and error handling to facilitate alerting and reduce TTD.    |\n",
      "| Observability | No Correlation IDs in logs for tracing errors.                     | High       | Implement Correlation IDs in logs to trace errors across various components.                      |\n",
      "| Observability | No mention of adjustable log levels for troubleshooting.           | Medium     | Ensure the service can support changing log levels for troubleshooting purposes.                  |\n",
      "| Observability | Unclear if critical log lines are identified for alerts.          | Medium     | Identify and implement alerts for critical log lines that indicate failures or important events.  |\n",
      "| Security      | Sensitive log lines not masked appropriately.                      | High       | Ensure that all sensitive log lines are masked to prevent exposure of sensitive information.      |\n",
      "| Security      | No information on secrets encryption at rest and in transit.       | High       | Implement encryption for all secrets both at rest and in transit.                                 |\n",
      "| Security      | No mention of data encryption at rest and in transit.              | High       | Ensure that all data is encrypted at rest and in transit to protect against unauthorized access.  |\n",
      "| Security      | No indication of using distroless/mariner base images.             | Medium     | Consider using distroless or mariner base images to enhance security posture.                     |\n",
      "\n",
      "### Conclusion\n",
      "The pull request introduces important changes but lacks sufficient observability and security measures. Addressing the identified gaps will enhance the robustness of the feature and ensure better monitoring and protection against potential vulnerabilities.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### Summary of Changes\\nThe pull request introduces modifications to the `CreateJobIfNotInProgress` function in the `database.go` file. The changes include:\\n1. Updating the SQL query to fetch both the job type and error message from the `JOB_STATUS` table instead of just checking for the existence of a job.\\n2. Adding logic to handle a specific error case where a baseline backup is already in progress, returning a more informative error message.\\n3. Corresponding updates to the unit tests to validate the new behavior, including a test for the new error handling.\\n\\n### Observability and Security Analysis\\n\\n#### Observability Gaps and Risks\\n1. **Actionable Alerts**: The changes do not specify if there are actionable alerts for the new error conditions introduced. \\n2. **Metrics for Monitoring**: There is no indication that metrics are being added to monitor the new error conditions or the job creation process.\\n3. **Correlation IDs**: The code does not show any implementation of Correlation IDs in logs, which would help trace errors across components.\\n4. **Log Levels**: There is no mention of the ability to change log levels for troubleshooting.\\n5. **Critical Log Lines**: While there are error logs, it is unclear if there are critical log lines that need alerts.\\n\\n#### Security Gaps and Risks\\n1. **Sensitive Log Lines**: The code does not indicate if sensitive information is being masked in logs.\\n2. **Secrets Management**: There is no information regarding the encryption of secrets at rest and in transit.\\n3. **Data Encryption**: The code does not specify if data is encrypted at rest and in transit.\\n4. **Base Image**: There is no mention of using distroless or mariner base images, which are recommended for security.\\n\\n### Observability and Security Risk Report\\n\\n| Area       | Gap                                                                 | Risk Level | Recommendation                                                                                     |\\n|------------|---------------------------------------------------------------------|------------|---------------------------------------------------------------------------------------------------|\\n| Observability | No actionable alerts for new error conditions.                     | High       | Define and implement actionable alerts for the new error conditions introduced in the PR.        |\\n| Observability | Lack of metrics for monitoring job creation and error handling.    | Medium     | Add metrics to monitor job creation and error handling to facilitate alerting and reduce TTD.    |\\n| Observability | No Correlation IDs in logs for tracing errors.                     | High       | Implement Correlation IDs in logs to trace errors across various components.                      |\\n| Observability | No mention of adjustable log levels for troubleshooting.           | Medium     | Ensure the service can support changing log levels for troubleshooting purposes.                  |\\n| Observability | Unclear if critical log lines are identified for alerts.          | Medium     | Identify and implement alerts for critical log lines that indicate failures or important events.  |\\n| Security      | Sensitive log lines not masked appropriately.                      | High       | Ensure that all sensitive log lines are masked to prevent exposure of sensitive information.      |\\n| Security      | No information on secrets encryption at rest and in transit.       | High       | Implement encryption for all secrets both at rest and in transit.                                 |\\n| Security      | No mention of data encryption at rest and in transit.              | High       | Ensure that all data is encrypted at rest and in transit to protect against unauthorized access.  |\\n| Security      | No indication of using distroless/mariner base images.             | Medium     | Consider using distroless or mariner base images to enhance security posture.                     |\\n\\n### Conclusion\\nThe pull request introduces important changes but lacks sufficient observability and security measures. Addressing the identified gaps will enhance the robustness of the feature and ensure better monitoring and protection against potential vulnerabilities.'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [fetchprdiff,\n",
    "        file_fetch_tool,\n",
    "        prometheus_metrics_fetch_tool,\n",
    "        # bandit_security_checker_tool\n",
    "        ]\n",
    "\n",
    "# repo_name=REPO_NAME\n",
    "# pr_number={PULL_REQUEST_NUMBER}\n",
    "# github_token={config.GITHUB_TOKEN} \n",
    "# human_message = f\"Analyze the {PULL_REQUEST_NUMBER} from {REPO_NAME}, Use {PULL_REQUEST_NUMBER} as pr_number and as {config.GITHUB_TOKEN} github_token\"\n",
    "\n",
    "# Instantiate the agent\n",
    "agent_instance = PRRAgent(config.llm, tools, prompt)\n",
    "\n",
    "# Prepare the input messages\n",
    "human_message = f\"Analyze the pull request {PULL_REQUEST_NUMBER} from {REPO_NAME}\"\n",
    "# human_message = f\"How are you doing?\"\n",
    "messages = [HumanMessage(content=human_message)]\n",
    "\n",
    "# Invoke the agent's graph and get the result\n",
    "result = agent_instance.graph.invoke({\"messages\": messages})\n",
    "\n",
    "# Print the agent's thought process and tool usage\n",
    "for msg in result['messages']:\n",
    "    if hasattr(msg, 'content') and msg.content:\n",
    "        print(f\"{msg.__class__.__name__}: {msg.content}\\n\")\n",
    "\n",
    "# Display the agent's response\n",
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "349e5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize the compiled agent graph\n",
    "display(Image(agent_instance.graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d474a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
