{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the llm proxy\n",
    "# import os\n",
    "# # pem_path = \"/opt/homebrew/etc/openssl@3/certs/../cert.pem\"\n",
    "# pem_path = \"/opt/homebrew/etc/openssl@3/cert.pem\"\n",
    "# # Ensure the environment variables are set before making the API call\n",
    "# os.environ['REQUESTS_CA_BUNDLE'] = pem_path\n",
    "# os.environ['SSL_CERT_FILE'] = pem_path\n",
    "\n",
    "# # Proceed with the API call\n",
    "# import getpass\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(\n",
    "#     base_url = os.getenv('proxyllmendpoint'),\n",
    "#     api_key  = os.getenv('proxyllmuserkey'), \n",
    "# )\n",
    "# completion =  client.chat.completions.create(\n",
    "#                     model    = \"gpt-4o-mini\",\n",
    "#                     messages = [{ \"role\"   : \"user\",\n",
    "#                                   \"content\": \"Write a function that prints n primes in python\"}],\n",
    "#                     user     = getpass.getuser() # DO NOT HARDCODE A USER HERE\n",
    "#                 )\n",
    "\n",
    "# import os\n",
    "# import getpass\n",
    "# pem_path = \"/opt/homebrew/etc/openssl@3/certs/../cert.pem\"\n",
    "# # Ensure the environment variables are set before making the API call\n",
    "# os.environ['REQUESTS_CA_BUNDLE'] = pem_path\n",
    "# # os.environ['SSL_CERT_FILE']      = pem_path\n",
    "\n",
    "# # Proceed with the API call\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(\n",
    "#     base_url = os.getenv('proxyllmendpoint'),\n",
    "#     api_key  = os.getenv('proxyllmappkey'), # DO NOT HARDCODE YOUR KEY\n",
    "# )\n",
    "# completion =  client.chat.completions.create(\n",
    "#                     model    = \"gpt-4o-mini\",\n",
    "#                     messages = [{ \"role\"   : \"user\",\n",
    "#                                   \"content\": \"Write a function that prints n primes in python\"}],\n",
    "#                     # user     = \"prragenticworkflow\" # DO NOT HARDCODE A USER HERE\n",
    "#                     user = getpass.getuser()\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilred/Library/Python/3.13/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import getpass # to get the current user\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain.chains import ConversationChain\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "import operator\n",
    "from semantic_router.utils.function_call import FunctionSchema\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining file read tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_python_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: File not found.\"\n",
    "    \n",
    "class codepath(BaseModel):\n",
    "  path: str = Field(description=\"code path to execute\")\n",
    "\n",
    "@tool(args_schema = codepath)\n",
    "def execute_query(path: str) -> str:\n",
    "  \"\"\"Returns the result of code path execution\"\"\"\n",
    "  return read_python_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': '40poc.ipynb', 'path': '40poc.ipynb', 'sha': 'cc060420615f0355ec0594976e64d64101f4a35f', 'size': 17192, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/40poc.ipynb?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/40poc.ipynb', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/cc060420615f0355ec0594976e64d64101f4a35f', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/40poc.ipynb', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/40poc.ipynb?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/cc060420615f0355ec0594976e64d64101f4a35f', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/40poc.ipynb'}}, {'name': 'README.md', 'path': 'README.md', 'sha': 'fe870f98874a6066f0bebf709443957a48babd0d', 'size': 31, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/README.md?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/README.md', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/fe870f98874a6066f0bebf709443957a48babd0d', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/README.md', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/README.md?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/fe870f98874a6066f0bebf709443957a48babd0d', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/README.md'}}, {'name': 'Streamlitapp', 'path': 'Streamlitapp', 'sha': '8b80289daa5bef51124f5b28de340c9c7483f3fd', 'size': 0, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/Streamlitapp?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/tree/main/Streamlitapp', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/trees/8b80289daa5bef51124f5b28de340c9c7483f3fd', 'download_url': None, 'type': 'dir', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/Streamlitapp?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/trees/8b80289daa5bef51124f5b28de340c9c7483f3fd', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/tree/main/Streamlitapp'}}, {'name': 'cbserrorlog.csv', 'path': 'cbserrorlog.csv', 'sha': '9bc121e50dfd4bf3eb3939a6806fc27d0637e117', 'size': 4153132, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/cbserrorlog.csv?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/cbserrorlog.csv', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/9bc121e50dfd4bf3eb3939a6806fc27d0637e117', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/cbserrorlog.csv', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/cbserrorlog.csv?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/9bc121e50dfd4bf3eb3939a6806fc27d0637e117', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/cbserrorlog.csv'}}, {'name': 'cvtmetricreceiverlog.csv', 'path': 'cvtmetricreceiverlog.csv', 'sha': 'b6b14ac1b7542b2603a432c905cfb793720ea77d', 'size': 33110, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/cvtmetricreceiverlog.csv?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/cvtmetricreceiverlog.csv', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/b6b14ac1b7542b2603a432c905cfb793720ea77d', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/cvtmetricreceiverlog.csv', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/cvtmetricreceiverlog.csv?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/b6b14ac1b7542b2603a432c905cfb793720ea77d', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/cvtmetricreceiverlog.csv'}}, {'name': 'llamapoc.ipynb', 'path': 'llamapoc.ipynb', 'sha': 'dcab3a12f01997b9c1194292829a356d55344b0f', 'size': 50182, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/llamapoc.ipynb?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/llamapoc.ipynb', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/dcab3a12f01997b9c1194292829a356d55344b0f', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/llamapoc.ipynb', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/llamapoc.ipynb?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/dcab3a12f01997b9c1194292829a356d55344b0f', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/llamapoc.ipynb'}}, {'name': 'logexample.csv', 'path': 'logexample.csv', 'sha': '3f8461d25cd4e199aa673e3d70b00bc2d6dd4c4f', 'size': 709, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/logexample.csv?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/logexample.csv', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/3f8461d25cd4e199aa673e3d70b00bc2d6dd4c4f', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/logexample.csv', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/logexample.csv?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/3f8461d25cd4e199aa673e3d70b00bc2d6dd4c4f', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/logexample.csv'}}, {'name': 'proxyllm.ipynb', 'path': 'proxyllm.ipynb', 'sha': '562bfd9fed112beb830baa15d042203b854d49bb', 'size': 13932, 'url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/proxyllm.ipynb?ref=main', 'html_url': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/proxyllm.ipynb', 'git_url': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/562bfd9fed112beb830baa15d042203b854d49bb', 'download_url': 'https://raw.githubusercontent.com/akhilntap/ProductionReadinessAgenticAI/main/proxyllm.ipynb', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/contents/proxyllm.ipynb?ref=main', 'git': 'https://api.github.com/repos/akhilntap/ProductionReadinessAgenticAI/git/blobs/562bfd9fed112beb830baa15d042203b854d49bb', 'html': 'https://github.com/akhilntap/ProductionReadinessAgenticAI/blob/main/proxyllm.ipynb'}}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>sha</th>\n",
       "      <th>size</th>\n",
       "      <th>url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>git_url</th>\n",
       "      <th>download_url</th>\n",
       "      <th>type</th>\n",
       "      <th>_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40poc.ipynb</td>\n",
       "      <td>40poc.ipynb</td>\n",
       "      <td>cc060420615f0355ec0594976e64d64101f4a35f</td>\n",
       "      <td>17192</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>README.md</td>\n",
       "      <td>README.md</td>\n",
       "      <td>fe870f98874a6066f0bebf709443957a48babd0d</td>\n",
       "      <td>31</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Streamlitapp</td>\n",
       "      <td>Streamlitapp</td>\n",
       "      <td>8b80289daa5bef51124f5b28de340c9c7483f3fd</td>\n",
       "      <td>0</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>None</td>\n",
       "      <td>dir</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbserrorlog.csv</td>\n",
       "      <td>cbserrorlog.csv</td>\n",
       "      <td>9bc121e50dfd4bf3eb3939a6806fc27d0637e117</td>\n",
       "      <td>4153132</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cvtmetricreceiverlog.csv</td>\n",
       "      <td>cvtmetricreceiverlog.csv</td>\n",
       "      <td>b6b14ac1b7542b2603a432c905cfb793720ea77d</td>\n",
       "      <td>33110</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llamapoc.ipynb</td>\n",
       "      <td>llamapoc.ipynb</td>\n",
       "      <td>dcab3a12f01997b9c1194292829a356d55344b0f</td>\n",
       "      <td>50182</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logexample.csv</td>\n",
       "      <td>logexample.csv</td>\n",
       "      <td>3f8461d25cd4e199aa673e3d70b00bc2d6dd4c4f</td>\n",
       "      <td>709</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proxyllm.ipynb</td>\n",
       "      <td>proxyllm.ipynb</td>\n",
       "      <td>562bfd9fed112beb830baa15d042203b854d49bb</td>\n",
       "      <td>13932</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://github.com/akhilntap/ProductionReadine...</td>\n",
       "      <td>https://api.github.com/repos/akhilntap/Product...</td>\n",
       "      <td>https://raw.githubusercontent.com/akhilntap/Pr...</td>\n",
       "      <td>file</td>\n",
       "      <td>{'self': 'https://api.github.com/repos/akhilnt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                      path  \\\n",
       "0               40poc.ipynb               40poc.ipynb   \n",
       "1                 README.md                 README.md   \n",
       "2              Streamlitapp              Streamlitapp   \n",
       "3           cbserrorlog.csv           cbserrorlog.csv   \n",
       "4  cvtmetricreceiverlog.csv  cvtmetricreceiverlog.csv   \n",
       "5            llamapoc.ipynb            llamapoc.ipynb   \n",
       "6            logexample.csv            logexample.csv   \n",
       "7            proxyllm.ipynb            proxyllm.ipynb   \n",
       "\n",
       "                                        sha     size  \\\n",
       "0  cc060420615f0355ec0594976e64d64101f4a35f    17192   \n",
       "1  fe870f98874a6066f0bebf709443957a48babd0d       31   \n",
       "2  8b80289daa5bef51124f5b28de340c9c7483f3fd        0   \n",
       "3  9bc121e50dfd4bf3eb3939a6806fc27d0637e117  4153132   \n",
       "4  b6b14ac1b7542b2603a432c905cfb793720ea77d    33110   \n",
       "5  dcab3a12f01997b9c1194292829a356d55344b0f    50182   \n",
       "6  3f8461d25cd4e199aa673e3d70b00bc2d6dd4c4f      709   \n",
       "7  562bfd9fed112beb830baa15d042203b854d49bb    13932   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/akhilntap/Product...   \n",
       "1  https://api.github.com/repos/akhilntap/Product...   \n",
       "2  https://api.github.com/repos/akhilntap/Product...   \n",
       "3  https://api.github.com/repos/akhilntap/Product...   \n",
       "4  https://api.github.com/repos/akhilntap/Product...   \n",
       "5  https://api.github.com/repos/akhilntap/Product...   \n",
       "6  https://api.github.com/repos/akhilntap/Product...   \n",
       "7  https://api.github.com/repos/akhilntap/Product...   \n",
       "\n",
       "                                            html_url  \\\n",
       "0  https://github.com/akhilntap/ProductionReadine...   \n",
       "1  https://github.com/akhilntap/ProductionReadine...   \n",
       "2  https://github.com/akhilntap/ProductionReadine...   \n",
       "3  https://github.com/akhilntap/ProductionReadine...   \n",
       "4  https://github.com/akhilntap/ProductionReadine...   \n",
       "5  https://github.com/akhilntap/ProductionReadine...   \n",
       "6  https://github.com/akhilntap/ProductionReadine...   \n",
       "7  https://github.com/akhilntap/ProductionReadine...   \n",
       "\n",
       "                                             git_url  \\\n",
       "0  https://api.github.com/repos/akhilntap/Product...   \n",
       "1  https://api.github.com/repos/akhilntap/Product...   \n",
       "2  https://api.github.com/repos/akhilntap/Product...   \n",
       "3  https://api.github.com/repos/akhilntap/Product...   \n",
       "4  https://api.github.com/repos/akhilntap/Product...   \n",
       "5  https://api.github.com/repos/akhilntap/Product...   \n",
       "6  https://api.github.com/repos/akhilntap/Product...   \n",
       "7  https://api.github.com/repos/akhilntap/Product...   \n",
       "\n",
       "                                        download_url  type  \\\n",
       "0  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "1  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "2                                               None   dir   \n",
       "3  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "4  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "5  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "6  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "7  https://raw.githubusercontent.com/akhilntap/Pr...  file   \n",
       "\n",
       "                                              _links  \n",
       "0  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "1  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "2  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "3  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "4  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "5  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "6  {'self': 'https://api.github.com/repos/akhilnt...  \n",
       "7  {'self': 'https://api.github.com/repos/akhilnt...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# Function to fetch repository contents from GitHub\n",
    "def get_repo_contents(repo_owner, repo_name, access_token):\n",
    "    \"\"\"\n",
    "    Fetch the contents of a repository from GitHub.\n",
    "\n",
    "    :param repo_owner: Owner of the repository\n",
    "    :param repo_name: Name of the repository\n",
    "    :param access_token: Personal access token for GitHub\n",
    "    :return: Repository contents as a list of files and directories\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {access_token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: Unable to fetch repository contents (Status Code: {response.status_code})\"\n",
    "\n",
    "# Example usage\n",
    "repo_owner = \"akhilntap\"\n",
    "repo_name = \"ProductionReadinessAgenticAI\"\n",
    "access_token = os.environ.get(\"githubpat\")\n",
    "repo_contents = get_repo_contents(repo_owner, repo_name, access_token)\n",
    "print(repo_contents)\n",
    "repo_table = pd.DataFrame(repo_contents)\n",
    "repo_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 1,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"/Users/akhilred/Library/Python/3.13/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\\n\",\n",
      "      \"  from .autonotebook import tqdm as notebook_tqdm\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"import os\\n\",\n",
      "    \"from azure.ai.inference import ChatCompletionsClient\\n\",\n",
      "    \"from azure.ai.inference.models import SystemMessage, UserMessage\\n\",\n",
      "    \"from azure.core.credentials import AzureKeyCredential\\n\",\n",
      "    \"\\n\",\n",
      "    \"from langchain_community.chat_models import ChatOpenAI\\n\",\n",
      "    \"from langchain_core.tools import tool\\n\",\n",
      "    \"from pydantic.v1 import BaseModel, Field\\n\",\n",
      "    \"from typing import Optional\\n\",\n",
      "    \"\\n\",\n",
      "    \"from langgraph.graph import StateGraph, END\\n\",\n",
      "    \"from typing import TypedDict, Annotated\\n\",\n",
      "    \"import operator\\n\",\n",
      "    \"from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\\n\",\n",
      "    \"import ollama\\n\",\n",
      "    \"\\n\",\n",
      "    \"from semantic_router.utils.function_call import FunctionSchema\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def read_python_file(file_path):\\n\",\n",
      "    \"    try:\\n\",\n",
      "    \"        with open(file_path, 'r') as file:\\n\",\n",
      "    \"            return file.read()\\n\",\n",
      "    \"    except FileNotFoundError:\\n\",\n",
      "    \"        return \\\"Error: File not found.\\\"\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 3,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"\\n\",\n",
      "    \"class codepath(BaseModel):\\n\",\n",
      "    \"  path: str = Field(description=\\\"code path to execute\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"@tool(args_schema = codepath)\\n\",\n",
      "    \"def execute_query(path: str) -> str:\\n\",\n",
      "    \"  \\\"\\\"\\\"Returns the result of code path execution\\\"\\\"\\\"\\n\",\n",
      "    \"  return read_python_file(path)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 4,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"\\n\",\n",
      "    \"# defining agent state\\n\",\n",
      "    \"class AgentState(TypedDict):\\n\",\n",
      "    \"   messages: Annotated[list[AnyMessage], operator.add]\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 5,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"{'type': 'function',\\n\",\n",
      "       \" 'function': {'name': 'read_python_file',\\n\",\n",
      "       \"  'description': 'None',\\n\",\n",
      "       \"  'parameters': {'type': 'object',\\n\",\n",
      "       \"   'properties': {'file_path': {'description': None, 'type': 'object'},\\n\",\n",
      "       \"    'description': None},\\n\",\n",
      "       \"   'required': []}}}\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 5,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"# create the function calling schema for ollama\\n\",\n",
      "    \"execute_query_schema = FunctionSchema(read_python_file).to_ollama()\\n\",\n",
      "    \"# execute_query_schema[\\\"function\\\"][\\\"parameters\\\"][\\\"properties\\\"][\\\"description\\\"] = None\\n\",\n",
      "    \"execute_query_schema[\\\"function\\\"][\\\"parameters\\\"][\\\"properties\\\"][\\\"description\\\"] = None\\n\",\n",
      "    \"execute_query_schema\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 6,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stderr\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"2025-03-26 15:12:55 - azure.core.pipeline.policies.http_logging_policy - INFO - _universal.py:509 - on_request() - Request URL: 'https://agenticaieastu6274613629.openai.azure.com/openai/deployments/gpt-4o-mini/info?api-version=REDACTED'\\n\",\n",
      "      \"Request method: 'GET'\\n\",\n",
      "      \"Request headers:\\n\",\n",
      "      \"    'Accept': 'application/json'\\n\",\n",
      "      \"    'x-ms-client-request-id': '15d349cc-0a87-11f0-81d4-52304e248077'\\n\",\n",
      "      \"    'api-key': 'REDACTED'\\n\",\n",
      "      \"    'User-Agent': 'langchain-azure-ai azsdk-python-ai-inference/1.0.0b9 Python/3.13.0 (macOS-15.3.2-arm64-arm-64bit-Mach-O)'\\n\",\n",
      "      \"    'Authorization': 'REDACTED'\\n\",\n",
      "      \"No body was attached to the request\\n\",\n",
      "      \"2025-03-26 15:12:55 - azure.core.pipeline.policies.http_logging_policy - INFO - _universal.py:545 - on_response() - Response status: 404\\n\",\n",
      "      \"Response headers:\\n\",\n",
      "      \"    'Content-Length': '56'\\n\",\n",
      "      \"    'Content-Type': 'application/json'\\n\",\n",
      "      \"    'apim-request-id': 'REDACTED'\\n\",\n",
      "      \"    'Strict-Transport-Security': 'REDACTED'\\n\",\n",
      "      \"    'x-content-type-options': 'REDACTED'\\n\",\n",
      "      \"    'Date': 'Wed, 26 Mar 2025 21:12:54 GMT'\\n\",\n",
      "      \"2025-03-26 15:12:55 - langchain_azure_ai.chat_models.inference - WARNING - inference.py:498 - initialize_client() - Endpoint 'https://agenticaieastu6274613629.openai.azure.com/openai/deployments/gpt-4o-mini' does not support model metadata retrieval. Unable to populate model attributes. If this endpoint supports multiple models, you may be forgetting to indicate `model_name` parameter.\\n\",\n",
      "      \"2025-03-26 15:12:55 - azure.core.pipeline.policies.http_logging_policy - INFO - _universal.py:506 - on_request() - Request URL: 'https://agenticaieastu6274613629.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=REDACTED'\\n\",\n",
      "      \"Request method: 'POST'\\n\",\n",
      "      \"Request headers:\\n\",\n",
      "      \"    'Content-Type': 'application/json'\\n\",\n",
      "      \"    'Content-Length': '1288'\\n\",\n",
      "      \"    'Accept': 'application/json'\\n\",\n",
      "      \"    'x-ms-client-request-id': '16163e58-0a87-11f0-81d4-52304e248077'\\n\",\n",
      "      \"    'api-key': 'REDACTED'\\n\",\n",
      "      \"    'User-Agent': 'langchain-azure-ai azsdk-python-ai-inference/1.0.0b9 Python/3.13.0 (macOS-15.3.2-arm64-arm-64bit-Mach-O)'\\n\",\n",
      "      \"    'Authorization': 'REDACTED'\\n\",\n",
      "      \"A body is sent with the request\\n\",\n",
      "      \"2025-03-26 15:12:56 - azure.core.pipeline.policies.http_logging_policy - INFO - _universal.py:545 - on_response() - Response status: 200\\n\",\n",
      "      \"Response headers:\\n\",\n",
      "      \"    'Content-Length': '1104'\\n\",\n",
      "      \"    'Content-Type': 'application/json'\\n\",\n",
      "      \"    'apim-request-id': 'REDACTED'\\n\",\n",
      "      \"    'Strict-Transport-Security': 'REDACTED'\\n\",\n",
      "      \"    'x-content-type-options': 'REDACTED'\\n\",\n",
      "      \"    'x-ms-region': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-remaining-requests': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-limit-requests': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-remaining-tokens': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-limit-tokens': 'REDACTED'\\n\",\n",
      "      \"    'cmp-upstream-response-duration': 'REDACTED'\\n\",\n",
      "      \"    'x-accel-buffering': 'REDACTED'\\n\",\n",
      "      \"    'x-aml-cluster': 'REDACTED'\\n\",\n",
      "      \"    'x-envoy-upstream-service-time': 'REDACTED'\\n\",\n",
      "      \"    'x-ms-rai-invoked': 'REDACTED'\\n\",\n",
      "      \"    'x-request-id': 'REDACTED'\\n\",\n",
      "      \"    'ms-azureml-model-time': 'REDACTED'\\n\",\n",
      "      \"    'x-ms-client-request-id': '16163e58-0a87-11f0-81d4-52304e248077'\\n\",\n",
      "      \"    'azureml-model-session': 'REDACTED'\\n\",\n",
      "      \"    'Date': 'Wed, 26 Mar 2025 21:12:55 GMT'\\n\",\n",
      "      \"2025-03-26 15:12:56 - azure.core.pipeline.policies.http_logging_policy - INFO - _universal.py:506 - on_request() - Request URL: 'https://agenticaieastu6274613629.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=REDACTED'\\n\",\n",
      "      \"Request method: 'POST'\\n\",\n",
      "      \"Request headers:\\n\",\n",
      "      \"    'Content-Type': 'application/json'\\n\",\n",
      "      \"    'Content-Length': '23958'\\n\",\n",
      "      \"    'Accept': 'application/json'\\n\",\n",
      "      \"    'x-ms-client-request-id': '1689acd0-0a87-11f0-81d4-52304e248077'\\n\",\n",
      "      \"    'api-key': 'REDACTED'\\n\",\n",
      "      \"    'User-Agent': 'langchain-azure-ai azsdk-python-ai-inference/1.0.0b9 Python/3.13.0 (macOS-15.3.2-arm64-arm-64bit-Mach-O)'\\n\",\n",
      "      \"    'Authorization': 'REDACTED'\\n\",\n",
      "      \"A body is sent with the request\\n\",\n",
      "      \"2025-03-26 15:13:03 - azure.core.pipeline.policies.http_logging_policy - INFO - _universal.py:545 - on_response() - Response status: 200\\n\",\n",
      "      \"Response headers:\\n\",\n",
      "      \"    'Content-Length': '3841'\\n\",\n",
      "      \"    'Content-Type': 'application/json'\\n\",\n",
      "      \"    'apim-request-id': 'REDACTED'\\n\",\n",
      "      \"    'Strict-Transport-Security': 'REDACTED'\\n\",\n",
      "      \"    'x-content-type-options': 'REDACTED'\\n\",\n",
      "      \"    'x-ms-region': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-remaining-requests': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-limit-requests': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-remaining-tokens': 'REDACTED'\\n\",\n",
      "      \"    'x-ratelimit-limit-tokens': 'REDACTED'\\n\",\n",
      "      \"    'cmp-upstream-response-duration': 'REDACTED'\\n\",\n",
      "      \"    'x-accel-buffering': 'REDACTED'\\n\",\n",
      "      \"    'x-aml-cluster': 'REDACTED'\\n\",\n",
      "      \"    'x-envoy-upstream-service-time': 'REDACTED'\\n\",\n",
      "      \"    'x-ms-rai-invoked': 'REDACTED'\\n\",\n",
      "      \"    'x-request-id': 'REDACTED'\\n\",\n",
      "      \"    'ms-azureml-model-time': 'REDACTED'\\n\",\n",
      "      \"    'x-ms-client-request-id': '1689acd0-0a87-11f0-81d4-52304e248077'\\n\",\n",
      "      \"    'azureml-model-session': 'REDACTED'\\n\",\n",
      "      \"    'Date': 'Wed, 26 Mar 2025 21:13:02 GMT'\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"class codeAgent:\\n\",\n",
      "    \"  # initialising the object\\n\",\n",
      "    \"  def __init__(self, model, tools, system_prompt = \\\"\\\"):\\n\",\n",
      "    \"    self.system_prompt = system_prompt\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # initialising graph with a state \\n\",\n",
      "    \"    graph = StateGraph(AgentState)\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # adding nodes \\n\",\n",
      "    \"    graph.add_node(\\\"llm\\\", self.call_llm)\\n\",\n",
      "    \"    graph.add_node(\\\"function\\\", self.execute_function)\\n\",\n",
      "    \"    graph.add_conditional_edges(\\n\",\n",
      "    \"      \\\"llm\\\",\\n\",\n",
      "    \"      self.exists_function_calling,\\n\",\n",
      "    \"      {True: \\\"function\\\", False: END}\\n\",\n",
      "    \"    )\\n\",\n",
      "    \"    graph.add_edge(\\\"function\\\", \\\"llm\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # setting starting point\\n\",\n",
      "    \"    graph.set_entry_point(\\\"llm\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"    self.graph = graph.compile()\\n\",\n",
      "    \"    self.tools = {t.name: t for t in tools}\\n\",\n",
      "    \"    self.model = model.bind_tools(tools)\\n\",\n",
      "    \"\\n\",\n",
      "    \"  def call_llm(self, state: AgentState):\\n\",\n",
      "    \"    messages = state['messages']\\n\",\n",
      "    \"    # adding system prompt if it's defined\\n\",\n",
      "    \"    if self.system_prompt:\\n\",\n",
      "    \"        messages = [SystemMessage(content=self.system_prompt)] + messages\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # calling LLM\\n\",\n",
      "    \"    message = self.model.invoke(messages)\\n\",\n",
      "    \"\\n\",\n",
      "    \"    return {'messages': [message]}\\n\",\n",
      "    \"  \\n\",\n",
      "    \"  def execute_function(self, state: AgentState):\\n\",\n",
      "    \"    tool_calls = state['messages'][-1].tool_calls\\n\",\n",
      "    \"\\n\",\n",
      "    \"    results = []\\n\",\n",
      "    \"    for tool in tool_calls:\\n\",\n",
      "    \"      # checking whether tool name is correct\\n\",\n",
      "    \"      if not tool['name'] in self.tools:\\n\",\n",
      "    \"        # returning error to the agent \\n\",\n",
      "    \"        result = \\\"Error: There's no such tool, please, try again\\\" \\n\",\n",
      "    \"      else:\\n\",\n",
      "    \"        # getting result from the tool\\n\",\n",
      "    \"        result = self.tools[tool['name']].invoke(tool['args'])\\n\",\n",
      "    \"\\n\",\n",
      "    \"      results.append(\\n\",\n",
      "    \"        ToolMessage(\\n\",\n",
      "    \"          tool_call_id=tool['id'], \\n\",\n",
      "    \"          name=tool['name'], \\n\",\n",
      "    \"          content=str(result)\\n\",\n",
      "    \"        )\\n\",\n",
      "    \"    )\\n\",\n",
      "    \"    return {'messages': results}\\n\",\n",
      "    \"  \\n\",\n",
      "    \"  def exists_function_calling(self, state: AgentState):\\n\",\n",
      "    \"    result = state['messages'][-1]\\n\",\n",
      "    \"    return len(result.tool_calls) > 0\\n\",\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"# from langchain_ollama import ChatOllama\\n\",\n",
      "    \"# model = ChatOllama(model=\\\"llama3.2:1b\\\")\\n\",\n",
      "    \"# # model = ChatOllama(model=\\\"codellama:latest\\\")\\n\",\n",
      "    \"\\n\",\n",
      "    \"# system prompt\\n\",\n",
      "    \"# prompt = '''You are a senior expert in reviewing python code. \\n\",\n",
      "    \"# So, you can help the team to review the code and provide feedback. \\n\",\n",
      "    \"# You are very accurate and take into account all the nuances in code.\\n\",\n",
      "    \"# Your goal is to provide the detailed documentation for any security issues in the code that will help users.'''\\n\",\n",
      "    \"\\n\",\n",
      "    \"prompt = '''You are a senior expert in reviewing code for observability. The best one that exists.\\n\",\n",
      "    \"Your goal is to analyze the code on the following questions \\n\",\n",
      "    \"1. Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?\\n\",\n",
      "    \"2. Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?\\n\",\n",
      "    \"3. Are there CorrelationIDs established in logs to derive error lineage across various components?\\n\",\n",
      "    \"4. Can the feature/service support changing log levels for troubleshooting purposes?\\n\",\n",
      "    \"5. Are there critical log lines that we need to get alerted upon?\\n\",\n",
      "    \"Provide response in the format as follows: {question: response}\\n\",\n",
      "    \"'''\\n\",\n",
      "    \"\\n\",\n",
      "    \"import os\\n\",\n",
      "    \"from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\\n\",\n",
      "    \"\\n\",\n",
      "    \"model = AzureAIChatCompletionsModel(\\n\",\n",
      "    \"    endpoint= os.getenv('azureaifoundry4oendpoint'),\\n\",\n",
      "    \"    credential=os.getenv('azureaifoundry4okey'),\\n\",\n",
      "    \"    model=\\\"gpt-4o-mini\\\",\\n\",\n",
      "    \")\\n\",\n",
      "    \"\\n\",\n",
      "    \"doc_agent = codeAgent(model, [execute_query], system_prompt=prompt)\\n\",\n",
      "    \"\\n\",\n",
      "    \"messages = [HumanMessage(content=\\\"the code is in the path '/Users/akhilred/Desktop/Billing Pyton Script/Billing_Usage_Extraction.py'. Analyze the code for observability requirements mentioned in the prompt\\\")]\\n\",\n",
      "    \"result = doc_agent.graph.invoke({\\\"messages\\\": messages})\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 7,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"Here is the analysis of the provided code regarding the observability requirements:\\n\",\n",
      "      \"\\n\",\n",
      "      \"1. **Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?**\\n\",\n",
      "      \"   - **Response:** The code does not include any built-in alerts, runbooks, or TSG (trouble shooting guides) frameworks. There is no logic in place to generate alerts related to failure conditions, such as unsuccessful data extraction or exceptions. It is recommended to implement appropriate monitoring and alerting mechanisms based on expected failure points.\\n\",\n",
      "      \"\\n\",\n",
      "      \"2. **Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?**\\n\",\n",
      "      \"   - **Response:** The code currently lacks metrics that would allow monitoring of dependencies or exception handling. It only catches `KustoServiceError` exceptions in the data extraction methods. Adding logging for successes, failures, execution time, and request statistics would significantly enhance observability. Consider using a metrics service or logging framework to capture these metrics.\\n\",\n",
      "      \"\\n\",\n",
      "      \"3. **Are there CorrelationIDs established in logs to derive error lineage across various components?**\\n\",\n",
      "      \"   - **Response:** There is no use of CorrelationIDs in the logging mechanism to track the lineage of errors across components. Implementing CorrelationIDs in log statements would help trace the flow of requests and errors through the system, aiding debugging and enhancing traceability.\\n\",\n",
      "      \"\\n\",\n",
      "      \"4. **Can the feature/service support changing log levels for troubleshooting purposes?**\\n\",\n",
      "      \"   - **Response:** The code does not appear to support changing log levels dynamically. To facilitate troubleshooting, consider integrating a logging framework (like Python's built-in `logging` module), which allows for log level configuration (e.g., DEBUG, INFO, WARNING, ERROR) that can be adjusted at runtime.\\n\",\n",
      "      \"\\n\",\n",
      "      \"5. **Are there critical log lines that we need to get alerted upon?**\\n\",\n",
      "      \"   - **Response:** The code currently has no alerts set for critical log lines. While it does include exception handling, there is no logging of these exceptions nor any mechanism to alert on critical failures. It is advisable to add structured logs for critical actions and failure points, as well as set up alerts for these logs based on their severity.\\n\",\n",
      "      \"\\n\",\n",
      "      \"In summary, while the code performs its intended functionality, it lacks robust observability features. Implementing alerting, logging, metrics collection, and correlation tracking will greatly enhance the maintainability and reliability of the system.\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"print(result['messages'][3].content)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.13.0\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 2\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fetch_file_content(repo_contents, file_name):\n",
    "    \"\"\"\n",
    "    Fetch the content of a specific file from the GitHub repository.\n",
    "\n",
    "    :param repo_contents: List of repository contents\n",
    "    :param file_name: Name of the file to fetch\n",
    "    :return: File content as a string or an error message\n",
    "    \"\"\"\n",
    "    # Find the file in the repository contents\n",
    "    file_info = next((item for item in repo_contents if item['name'] == file_name), None)\n",
    "    \n",
    "    if not file_info:\n",
    "        return f\"Error: File '{file_name}' not found in the repository.\"\n",
    "    \n",
    "    if not file_info.get('download_url'):\n",
    "        return f\"Error: File '{file_name}' does not have a downloadable URL.\"\n",
    "    \n",
    "    # Fetch the file content\n",
    "    response = requests.get(file_info['download_url'])\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return f\"Error: Unable to fetch file content (Status Code: {response.status_code})\"\n",
    "\n",
    "# Example usage\n",
    "file_name = \"40poc.ipynb\" \n",
    "file_content = fetch_file_content(repo_contents, file_name)\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'read_python_file',\n",
       "  'description': 'None',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'file_path': {'description': None, 'type': 'object'},\n",
       "    'description': None},\n",
       "   'required': []}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the function calling schema for ollama\n",
    "execute_query_schema = FunctionSchema(read_python_file).to_ollama()\n",
    "# execute_query_schema[\"function\"][\"parameters\"][\"properties\"][\"description\"] = None\n",
    "execute_query_schema[\"function\"][\"parameters\"][\"properties\"][\"description\"] = None\n",
    "execute_query_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 15:04:13 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llm-proxy-api.ai.openeng.netapp.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-14 15:04:16 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llm-proxy-api.ai.openeng.netapp.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "class codeAgent:\n",
    "  # initialising the object\n",
    "  def __init__(self, model, tools, system_prompt = \"\"):\n",
    "    self.system_prompt = system_prompt\n",
    "\n",
    "    # initialising graph with a state \n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    # adding nodes \n",
    "    graph.add_node(\"llm\", self.call_llm)\n",
    "    graph.add_node(\"function\", self.execute_function)\n",
    "    graph.add_conditional_edges(\n",
    "      \"llm\",\n",
    "      self.exists_function_calling,\n",
    "      {True: \"function\", False: END}\n",
    "    )\n",
    "    graph.add_edge(\"function\", \"llm\")\n",
    "\n",
    "    # setting starting point\n",
    "    graph.set_entry_point(\"llm\")\n",
    "\n",
    "    self.graph = graph.compile()\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "    self.model = model.bind_tools(tools)\n",
    "\n",
    "  def call_llm(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    # adding system prompt if it's defined\n",
    "    if self.system_prompt:\n",
    "        messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "\n",
    "    # calling LLM\n",
    "    message = self.model.invoke(messages)\n",
    "\n",
    "    return {'messages': [message]}\n",
    "  \n",
    "  def execute_function(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    results = []\n",
    "    for tool in tool_calls:\n",
    "      # checking whether tool name is correct\n",
    "      if not tool['name'] in self.tools:\n",
    "        # returning error to the agent \n",
    "        result = \"Error: There's no such tool, please, try again\" \n",
    "      else:\n",
    "        # getting result from the tool\n",
    "        result = self.tools[tool['name']].invoke(tool['args'])\n",
    "\n",
    "      results.append(\n",
    "        ToolMessage(\n",
    "          tool_call_id=tool['id'], \n",
    "          name=tool['name'], \n",
    "          content=str(result)\n",
    "        )\n",
    "    )\n",
    "    return {'messages': results}\n",
    "  \n",
    "  def exists_function_calling(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "\n",
    "# from langchain_ollama import ChatOllama\n",
    "# model = ChatOllama(model=\"llama3.2:1b\")\n",
    "# # model = ChatOllama(model=\"codellama:latest\")\n",
    "\n",
    "# system prompt\n",
    "# prompt = '''You are a senior expert in reviewing python code. \n",
    "# So, you can help the team to review the code and provide feedback. \n",
    "# You are very accurate and take into account all the nuances in code.\n",
    "# Your goal is to provide the detailed documentation for any security issues in the code that will help users.'''\n",
    "\n",
    "# prompt = '''You are a senior expert in reviewing code for observability. The best one that exists.\n",
    "# Your goal is to analyze the code on the following questions \n",
    "# 1. Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?\n",
    "# 2. Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?\n",
    "# 3. Are there CorrelationIDs established in logs to derive error lineage across various components?\n",
    "# 4. Can the feature/service support changing log levels for troubleshooting purposes?\n",
    "# 5. Are there critical log lines that we need to get alerted upon?\n",
    "# Provide response in the format as follows: {question: response}\n",
    "# '''\n",
    "\n",
    "prompt = '''You are a senior expert in reviewing code for resiliency. The best one that exists.\n",
    "Your goal is to analyze the code on the following questions \n",
    "1. Can the service/feature sustain a single node/pod failure?\n",
    "2. Can the feature/service recover gracefully without requiring a restart?\n",
    "3. Are there conditions that will require a human intervention to start the pods? if so, what are they?\n",
    "4. What will be the customer impact(if any) due to lack of high availability?\n",
    "Provide response in the format as follows: {question: response}\n",
    "'''\n",
    "\n",
    "#  getting the required ssl certificates\n",
    "pem_path = \"/opt/homebrew/etc/openssl@3/cert.pem\"\n",
    "# Ensure the environment variables are set before making the API call\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = pem_path\n",
    "os.environ['SSL_CERT_FILE'] = pem_path\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model_name      = \"gpt-4o-mini\",\n",
    "                 openai_api_base = os.getenv('proxyllmendpoint'),\n",
    "                 openai_api_key  = os.getenv('proxyllmuserkey'),\n",
    "                 model_kwargs    = {'user': getpass.getuser() })\n",
    "\n",
    "doc_agent = codeAgent(model, [execute_query], system_prompt=prompt)\n",
    "\n",
    "messages = [HumanMessage(content=\"the code is in the path '/Users/akhilred/Desktop/Billing Pyton Script/Billing_Usage_Extraction.py'. Analyze the code for resiliency requirements mentioned in the prompt\")]\n",
    "result = doc_agent.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"1\": \"The service can sustain a single node/pod failure to some extent, as it utilizes Azure Kusto's querying capabilities which distribute load across multiple nodes. However, if the entire service instance fails (i.e., the instance where the script is running), or if there are issues with the authentication mechanism or data source configuration, data extraction will be halted.\",\n",
      "  \"2\": \"The feature is designed to recover gracefully in terms of handling exceptions during Kusto queries, specifically with try-except blocks in the get_data_for_usage_app_auth and get_data_for_usage_gov_app_auth functions. However, if the entire service or script is terminated, it would require a restart to resume functioning, as there is no implemented retry logic or fallback mechanisms in place.\",\n",
      "  \"3\": \"Conditions that will require human intervention include: \\n- Authentication errors where a user needs to input secrets manually. \\n- Kusto query failures as logged in the exceptions, which will require investigation of the conditions that caused the queries to fail. \\n- Issues related to path validation for downloading CSV files, as incorrect paths will hinder file creation.\",\n",
      "  \"4\": \"Customer impact due to lack of high availability may include data access delays or complete unavailability of the queried billing and usage data. This may disrupt operational processes that rely on timely data extraction for analytics and decision-making, potentially leading to financial and operational inefficiencies.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
