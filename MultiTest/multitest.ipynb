{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be20361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import initialize_agent, Tool\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "import operator\n",
    "# from langchain.prompts import PromptTemplate\n",
    "import requests\n",
    "from github import Github\n",
    "import os\n",
    "import getpass\n",
    "from bandit.core import manager, config\n",
    "from azure.identity import ManagedIdentityCredential\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db4e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Config ===\n",
    "REPO_NAME = \"greenqloud/cloud-backup-service\"\n",
    "PULL_REQUEST_NUMBER = 1853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c1134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === LangChain LLM ===\n",
    "# #  getting the required ssl certificates\n",
    "# pem_path = \"/opt/homebrew/etc/openssl@3/cert.pem\"\n",
    "# # Ensure the environment variables are set before making the API call\n",
    "# os.environ['REQUESTS_CA_BUNDLE'] = pem_path\n",
    "# os.environ['SSL_CERT_FILE'] = pem_path\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model_name      = \"gpt-4o-mini\",\n",
    "#                  openai_api_base = config.OPENAI_ENDPOINT,\n",
    "#                  openai_api_key  = config.OPENAI_API_KEY,\n",
    "#                  model_kwargs    = {'user': getpass.getuser() },\n",
    "#                  temperature = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7f4cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tool 1: GitHub PR Fetcher ===\n",
    "def fetch_pr_diff_and_metadata(repo_name=REPO_NAME, pr_number=PULL_REQUEST_NUMBER, github_token=config.GITHUB_TOKEN):\n",
    "    \"\"\"\n",
    "    Fetch pull request metadata and diff from GitHub.\n",
    "\n",
    "    Args:\n",
    "        repo_name (str): The full repository name (e.g., \"owner/repo\").\n",
    "        pr_number (int): The pull request number.\n",
    "        github_token (str): GitHub personal access token.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "    \"\"\"\n",
    "    g = Github(github_token)\n",
    "    repo = g.get_repo(repo_name)\n",
    "    pr = repo.get_pull(pr_number)\n",
    "    pr_title = pr.title\n",
    "    pr_body = pr.body\n",
    "    diff_response = requests.get(\n",
    "        f\"https://api.github.com/repos/{repo_name}/pulls/{pr_number}\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"token {github_token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "        }\n",
    "    )\n",
    "    diff_text = diff_response.text\n",
    "    return diff_text\n",
    "class prrepo(BaseModel):\n",
    "    repo_name: str = Field(description=\"Repo to execute\")\n",
    "    pr_number: int = Field(description=\"PR number to execute\")\n",
    "@tool(args_schema = prrepo)\n",
    "def fetchprdiff(repo_name: str, pr_number: int) -> str:\n",
    "  \"\"\"Returns the result of diff text in a PR\"\"\"\n",
    "  return fetch_pr_diff_and_metadata(repo_name, pr_number, github_token=config.GITHUB_TOKEN)\n",
    "\n",
    "\n",
    "# === Tool 1: GitHub File Fetcher ===\n",
    "def get_file_context(filename, ref=\"master\"):\n",
    "    g = Github(config.GITHUB_TOKEN)\n",
    "    repo = g.get_repo(REPO_NAME)\n",
    "    try:\n",
    "        contents = repo.get_contents(filename, ref=ref)\n",
    "        return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching file {filename}: {e}\"\n",
    "# Tool for langrgaph\n",
    "\n",
    "class filecontent(BaseModel):\n",
    "    filename: str = Field(description=\"Get full contents of file\")\n",
    "@tool(args_schema = filecontent)\n",
    "def file_fetch_tool(filename: str, ref: str = \"master\") -> str:\n",
    "   \"\"\"\n",
    "    Fetch full content of a given file from the repo for additional context.\n",
    "    \"\"\"\n",
    "   return get_file_context(filename, ref=\"master\")\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 2: Prometheus metrics fetcher ===\n",
    "def get_prometheus_metrics(prometheus_url):\n",
    "    try:\n",
    "        credential = ManagedIdentityCredential(client_id=os.getenv(\"prometheus_client_id\"))\n",
    "        token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\"\n",
    "        }\n",
    "        response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data.get('status') == 'success':\n",
    "            return data.get('data', [])\n",
    "        else:\n",
    "            print(f\"Error from Prometheus API: {data}\")\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request failed: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "# Tool for LangGraph\n",
    "class prometheusmetricsurl(BaseModel):\n",
    "    prometheus_url: str = Field(description=\"Get full contents of file\")\n",
    "@tool(args_schema = prometheusmetricsurl)\n",
    "def prometheus_metrics_fetch_tool(prometheus_url: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all the prometheus metrics from azure monitor workspace to get context for observability.\n",
    "    \"\"\"\n",
    "    return get_prometheus_metrics(prometheus_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "#place holder to add - copy from saw\n",
    "\n",
    "# === Tool 4: Bandit Code Security checker ===\n",
    "def check_code_security(file_path):\n",
    "    \"\"\"\n",
    "    Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "    :param file_path: Path to the Python file to analyze\n",
    "    :return: Bandit report as a string\n",
    "    \"\"\"\n",
    "    # Load Bandit configuration\n",
    "    bandit_config = config.BanditConfig()\n",
    "\n",
    "    # Initialize Bandit manager\n",
    "    bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "    # Run Bandit on the specified file\n",
    "    bandit_manager.discover_files([file_path])\n",
    "    bandit_manager.run_tests()\n",
    "\n",
    "    # Generate and return the report\n",
    "    issues = bandit_manager.get_issue_list()\n",
    "    if not issues:\n",
    "        return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "    # If no high-level issues, check for lower-level issues\n",
    "    lower_level_issues = []\n",
    "    for issue in issues:\n",
    "        if issue.severity.lower() in ['low', 'medium']:\n",
    "            lower_level_issues.append(str(issue))\n",
    "\n",
    "    if lower_level_issues:\n",
    "        return \"\\n\".join(lower_level_issues)\n",
    "    else:\n",
    "        return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# Tool wrapper for LangChain\n",
    "class banditsecurity(BaseModel):\n",
    "    file_path: str = Field(description=\"Get path of file to execute\")\n",
    "@tool(args_schema = banditsecurity)\n",
    "def bandit_security_checker_tool(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Check security of a python code using bandit library.\n",
    "    \"\"\"\n",
    "    return check_code_security(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d508e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Tool 1: GitHub PR Fetcher ===\n",
    "# def fetch_pr_diff_and_metadata(repo_name, pr_number, github_token):\n",
    "#     \"\"\"\n",
    "#     Fetch pull request metadata and diff from GitHub.\n",
    "\n",
    "#     Args:\n",
    "#         repo_name (str): The full repository name (e.g., \"owner/repo\").\n",
    "#         pr_number (int): The pull request number.\n",
    "#         github_token (str): GitHub personal access token.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "#     \"\"\"\n",
    "#     g = Github(github_token)\n",
    "#     repo = g.get_repo(repo_name)\n",
    "#     pr = repo.get_pull(pr_number)\n",
    "#     pr_title = pr.title\n",
    "#     pr_body = pr.body\n",
    "#     diff_response = requests.get(\n",
    "#         f\"https://api.github.com/repos/{repo_name}/pulls/{pr_number}\",\n",
    "#         headers={\n",
    "#             \"Authorization\": f\"token {github_token}\",\n",
    "#             \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "#         }\n",
    "#     )\n",
    "#     diff_text = diff_response.text\n",
    "#     return diff_text\n",
    "# # Tool for langrgaph\n",
    "# @tool\n",
    "# def pr_diff_and_metadata_fetch_tool(repo_name: str, pr_number: int, github_token: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Fetch pull request metadata and diff from GitHub.\n",
    "#     Returns a dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "#     \"\"\"\n",
    "#     pr, diff_text = fetch_pr_diff_and_metadata(repo_name, pr_number, github_token)\n",
    "#     return {\n",
    "#         \"pr_title\": pr.title,\n",
    "#         \"pr_body\": pr.body,\n",
    "#         \"diff_text\": diff_text\n",
    "#     }\n",
    "\n",
    "# # === Tool 1: GitHub File Fetcher ===\n",
    "# def get_file_context(filename, ref=\"master\"):\n",
    "#     g = Github(config.GITHUB_TOKEN)\n",
    "#     repo = g.get_repo(REPO_NAME)\n",
    "#     try:\n",
    "#         contents = repo.get_contents(filename, ref=ref)\n",
    "#         return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "#     except Exception as e:\n",
    "#         return f\"Error fetching file {filename}: {e}\"\n",
    "# # Tool for langrgaph\n",
    "# @tool\n",
    "# def file_fetch_tool(filename: str, ref: str = \"master\") -> str:\n",
    "#     \"\"\"\n",
    "#     Fetch full content of a given file from the repo for additional context.\n",
    "#     \"\"\"\n",
    "#     return get_file_context(filename, ref=\"master\")\n",
    "\n",
    "\n",
    "# # === Tool 2: Prometheus metrics fetcher ===\n",
    "# def get_prometheus_metrics(prometheus_url):\n",
    "#     try:\n",
    "#         credential = ManagedIdentityCredential(client_id=os.getenv(\"prometheus_client_id\"))\n",
    "#         token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "#         headers = {\n",
    "#             \"Authorization\": f\"Bearer {token}\"\n",
    "#         }\n",
    "#         response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "#         if data.get('status') == 'success':\n",
    "#             return data.get('data', [])\n",
    "#         else:\n",
    "#             print(f\"Error from Prometheus API: {data}\")\n",
    "#             return []\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"HTTP request failed: {e}\")\n",
    "#         return []\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         return []\n",
    "# # Tool for LangGraph\n",
    "# @tool\n",
    "# def prometheus_metrics_fetch_tool(prometheus_url: str) -> list:\n",
    "#     \"\"\"\n",
    "#     Fetch all the prometheus metrics from azure monitor workspace to get context for observability.\n",
    "#     \"\"\"\n",
    "#     return get_prometheus_metrics(prometheus_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "# #place holder to add - copy from saw\n",
    "\n",
    "# # === Tool 4: Bandit Code Security checker ===\n",
    "# def check_code_security(file_path):\n",
    "#     \"\"\"\n",
    "#     Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "#     :param file_path: Path to the Python file to analyze\n",
    "#     :return: Bandit report as a string\n",
    "#     \"\"\"\n",
    "#     # Load Bandit configuration\n",
    "#     bandit_config = config.BanditConfig()\n",
    "\n",
    "#     # Initialize Bandit manager\n",
    "#     bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "#     # Run Bandit on the specified file\n",
    "#     bandit_manager.discover_files([file_path])\n",
    "#     bandit_manager.run_tests()\n",
    "\n",
    "#     # Generate and return the report\n",
    "#     issues = bandit_manager.get_issue_list()\n",
    "#     if not issues:\n",
    "#         return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "#     # If no high-level issues, check for lower-level issues\n",
    "#     lower_level_issues = []\n",
    "#     for issue in issues:\n",
    "#         if issue.severity.lower() in ['low', 'medium']:\n",
    "#             lower_level_issues.append(str(issue))\n",
    "\n",
    "#     if lower_level_issues:\n",
    "#         return \"\\n\".join(lower_level_issues)\n",
    "#     else:\n",
    "#         return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# # Tool wrapper for LangChain\n",
    "# @tool\n",
    "# def bandit_security_checker_tool(file_path: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Check security of a python code using bandit library.\n",
    "#     \"\"\"\n",
    "#     return check_code_security(file_path)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e93f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Tool 1: GitHub File Fetcher ===\n",
    "# def get_file_context(filename, ref=\"master\"):\n",
    "#     g = Github(config.GITHUB_TOKEN)\n",
    "#     repo = g.get_repo(REPO_NAME)\n",
    "#     try:\n",
    "#         contents = repo.get_contents(filename, ref=ref)\n",
    "#         return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "#     except Exception as e:\n",
    "#         return f\"Error fetching file {filename}: {e}\"\n",
    "# # Tool wrapper for LangChain\n",
    "# file_fetch_tool = Tool(\n",
    "#     name=\"FileFetcher\",\n",
    "#     func=lambda filename: get_file_context(filename, ref=\"master\"),\n",
    "#     description=\"Fetch full content of a given file from the repo for additional context\"\n",
    "# )\n",
    "\n",
    "# # === Tool 2: Prometheus metrics fetcher ===\n",
    "# def get_prometheus_metrics(prometheus_url):\n",
    "#     try:\n",
    "#         credential = ManagedIdentityCredential(client_id=os.getenv(\"prometheus_client_id\"))\n",
    "#         token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "#         headers = {\n",
    "#             \"Authorization\": f\"Bearer {token}\"\n",
    "#         }\n",
    "#         response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "#         if data.get('status') == 'success':\n",
    "#             return data.get('data', [])\n",
    "#         else:\n",
    "#             print(f\"Error from Prometheus API: {data}\")\n",
    "#             return []\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"HTTP request failed: {e}\")\n",
    "#         return []\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         return []\n",
    "# # Tool wrapper for LangChain\n",
    "# prometheus_metrics_fetch_tool = Tool(\n",
    "#     name=\"PrometheusMetricsFetcher\",\n",
    "#     func=lambda prometheus_url: get_prometheus_metrics(prometheus_url),\n",
    "#     description=\"Fetch all the prometheus metrics from azure monitor workspace to get context for observability\"\n",
    "# )\n",
    "# # === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "# #place holder to add - copy from saw\n",
    "\n",
    "# # === Tool 4: Bandit Code Security checker ===\n",
    "# def check_code_security(file_path):\n",
    "#     \"\"\"\n",
    "#     Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "#     :param file_path: Path to the Python file to analyze\n",
    "#     :return: Bandit report as a string\n",
    "#     \"\"\"\n",
    "#     # Load Bandit configuration\n",
    "#     bandit_config = config.BanditConfig()\n",
    "\n",
    "#     # Initialize Bandit manager\n",
    "#     bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "#     # Run Bandit on the specified file\n",
    "#     bandit_manager.discover_files([file_path])\n",
    "#     bandit_manager.run_tests()\n",
    "\n",
    "#     # Generate and return the report\n",
    "#     issues = bandit_manager.get_issue_list()\n",
    "#     if not issues:\n",
    "#         return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "#     # If no high-level issues, check for lower-level issues\n",
    "#     lower_level_issues = []\n",
    "#     for issue in issues:\n",
    "#         if issue.severity.lower() in ['low', 'medium']:\n",
    "#             lower_level_issues.append(str(issue))\n",
    "\n",
    "#     if lower_level_issues:\n",
    "#         return \"\\n\".join(lower_level_issues)\n",
    "#     else:\n",
    "#         return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# # Tool wrapper for LangChain\n",
    "# bandit_security_checker_tool = Tool(\n",
    "#     name=\"BanditSecurityChecker\",\n",
    "#     func=lambda file_path: check_code_security(file_path),\n",
    "#     description=\"Check security of a python code using bandit library\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f585130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "801b8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = Github(config.GITHUB_TOKEN)\n",
    "# repo = g.get_repo(REPO_NAME)\n",
    "# pr = repo.get_pull(PULL_REQUEST_NUMBER)\n",
    "# pr_title = pr.title\n",
    "# pr_body = pr.body\n",
    "# diff_response = requests.get(\n",
    "#     f\"https://api.github.com/repos/{REPO_NAME}/pulls/{PULL_REQUEST_NUMBER}\",\n",
    "#     headers={\n",
    "#         \"Authorization\": f\"token {config.GITHUB_TOKEN}\",\n",
    "#         \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "#     }\n",
    "# )\n",
    "# diff_text = diff_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "846a1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Step 2: Build Agent Prompt ===\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"diff\", \"title\", \"description\"],\n",
    "#     template=\"\"\"\n",
    "# You are a senior AI engineer agent. you would wear multiple hats in the fields of observability and security\n",
    "# TASK:\n",
    "# Analyze the given pull request diff for potential observability and security issues.\n",
    "# Use a checklist for each area:\n",
    "# For observability:\n",
    "# - Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?\n",
    "# - Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?\n",
    "# - Are there CorrelationIDs established in logs to derive error lineage across various components?\n",
    "# - Can the feature/service support changing log levels for troubleshooting purposes?\n",
    "# - Are there critical log lines that we need to get alerted upon?\n",
    "# For Security \n",
    "# - All sensitive log lines are masked appropriately?\n",
    "# - Are all secrets encrypted at rest and in transit?\n",
    "# - Are all data encrypted at rest and in transit?\n",
    "# - Are we using distroless/mariner base image/s?\n",
    "# If the diff is unclear, use the FileFetcher tool to retrieve extra context of the file.\n",
    "# Pull Request Title:\n",
    "# {title}\n",
    "# Pull Request Description:\n",
    "# {description}\n",
    "# Diff:\n",
    "# {diff}\n",
    "# If the file has import from custom modules use the FileFetcher tool to retreive the file\n",
    "# Tell me if you fetched files for additional context\n",
    "# Begin step-by-step reasoning.\n",
    "# First, summarize what the change is doing.\n",
    "# Then, identify observability gaps and risky areas.\n",
    "# Finally, provide a observability and security risk report.\n",
    "# \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8dcffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Step 3: Initialize LangChain Agent ===\n",
    "# agent = initialize_agent(\n",
    "#     tools=[file_fetch_tool],\n",
    "#     agent=\"chat-conversational-react-description\",\n",
    "#     llm=config.llm,\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a133ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === Step 4: Run the Agent ===\n",
    "# input_prompt = prompt_template.format(\n",
    "#     diff=diff_text,\n",
    "#     title=pr.title,\n",
    "#     description=pr.body\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4f90a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent.run({\"input\": input_prompt, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dec9ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Step 5: Output the result ===\n",
    "# print(\"\\n=== Security Agent Report ===\\n\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "206fa2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent state\n",
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3e0cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRRAgent:\n",
    "  # initialising the object\n",
    "  def __init__(self, model, tools, system_prompt = \"\"):\n",
    "    self.system_prompt = system_prompt\n",
    "\n",
    "    # initialising graph with a state \n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    # adding nodes \n",
    "    graph.add_node(\"llm\", self.call_llm)\n",
    "    graph.add_node(\"function\", self.execute_function)\n",
    "    graph.add_conditional_edges(\n",
    "      \"llm\",\n",
    "      self.exists_function_calling,\n",
    "      {True: \"function\", False: END}\n",
    "    )\n",
    "    graph.add_edge(\"function\", \"llm\")\n",
    "\n",
    "    # setting starting point\n",
    "    graph.set_entry_point(\"llm\")\n",
    "\n",
    "    self.graph = graph.compile()\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "    self.model = model.bind_tools(tools)\n",
    "\n",
    "  def call_llm(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    # adding system prompt if it's defined\n",
    "    if self.system_prompt:\n",
    "        messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "\n",
    "    # calling LLM\n",
    "    message = self.model.invoke(messages)\n",
    "\n",
    "    return {'messages': [message]}\n",
    "  \n",
    "  def execute_function(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    results = []\n",
    "    for tool in tool_calls:\n",
    "      # checking whether tool name is correct\n",
    "      if not tool['name'] in self.tools:\n",
    "        # returning error to the agent \n",
    "        result = \"Error: There's no such tool, please, try again\" \n",
    "      else:\n",
    "        # getting result from the tool\n",
    "        result = self.tools[tool['name']].invoke(tool['args'])\n",
    "\n",
    "      results.append(\n",
    "        ToolMessage(\n",
    "          tool_call_id=tool['id'], \n",
    "          name=tool['name'], \n",
    "          content=str(result)\n",
    "        )\n",
    "    )\n",
    "    return {'messages': results}\n",
    "  \n",
    "  def exists_function_calling(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff8bd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Request Title:\n",
    "# {title}\n",
    "# Pull Request Description:\n",
    "# {description}\n",
    "# Diff:\n",
    "# {diff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd9b9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a senior AI engineer agent. you would wear multiple hats in the fields of observability and security\n",
    "TASK:\n",
    "Analyze the given pull request diff for potential observability and security issues.\n",
    "Use fetchprdiff tool to fetch the diff on a pull request\n",
    "Use a checklist for each area:\n",
    "For observability:\n",
    "- Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert?\n",
    "- Add metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD?\n",
    "- Are there CorrelationIDs established in logs to derive error lineage across various components?\n",
    "- Can the feature/service support changing log levels for troubleshooting purposes?\n",
    "- Are there critical log lines that we need to get alerted upon?\n",
    "For Security \n",
    "- All sensitive log lines are masked appropriately?\n",
    "- Are all secrets encrypted at rest and in transit?\n",
    "- Are all data encrypted at rest and in transit?\n",
    "- Are we using distroless/mariner base image/s?\n",
    "If the diff is unclear, use the FileFetcher tool to retrieve extra context of the file.\n",
    "If the file has import from custom modules use the FileFetcher tool to retreive the file\n",
    "Tell me if you fetched files for additional context\n",
    "Begin step-by-step reasoning.\n",
    "First, summarize what the change is doing.\n",
    "Then, identify observability gaps and risky areas.\n",
    "Finally, provide a observability and security risk report.\n",
    "'''\n",
    "# tools = [pr_diff_and_metadata_fetch_tool,\n",
    "#         file_fetch_tool,\n",
    "#         prometheus_metrics_fetch_tool,\n",
    "#         bandit_security_checker_tool]\n",
    "# human_message = \"Analyze the pr for observability requiremnts\"\n",
    "# doc_agent = PRRAgent(model = config.llm, tools=tools, system_prompt=prompt)\n",
    "# messages = [HumanMessage(content=human_message)]\n",
    "# result = doc_agent.graph.invoke({\"messages\": messages})\n",
    "# result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "53b84345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Summary of Changes\\n\\nThe pull request introduces modifications to the `CreateJobIfNotInProgress` function in the `database.go` file and adds a new test case in `miscellaneous_test.go`. The key changes include:\\n\\n1. **Error Handling Enhancement**: The SQL query now retrieves both the job type and error message from the `JOB_STATUS` table instead of just checking for the existence of a job. This allows for more detailed error handling.\\n2. **New Error Condition**: If a job of type `ScheduledBackupWithPolicyJobType` is found and the error message matches `GSProcessingError`, a specific error is returned indicating that a baseline backup is in progress.\\n3. **Test Case Addition**: A new test case is added to validate the behavior when a job exists with the `GSProcessingError`.\\n\\n### Observability Gaps and Risky Areas\\n\\n#### Observability Checklist\\n1. **Actionable Alerts**: \\n   - No actionable alerts are identified in the changes. There is no mention of runbooks or TSGs for the new error handling.\\n   \\n2. **Metrics for Monitoring**: \\n   - There are no metrics added to monitor dependencies or exception handling. This could lead to challenges in reducing Time to Detection (TTD) for issues.\\n\\n3. **Correlation IDs**: \\n   - There is no indication that Correlation IDs are established in logs, which would help in tracing errors across components.\\n\\n4. **Log Level Changes**: \\n   - The feature does not support changing log levels for troubleshooting purposes, which could hinder debugging efforts.\\n\\n5. **Critical Log Lines**: \\n   - While there are error logs being generated, it is unclear if there are critical log lines that need alerts. The logging of job existence and error messages should be reviewed for criticality.\\n\\n#### Security Checklist\\n1. **Sensitive Log Lines**: \\n   - The changes do not indicate whether sensitive log lines are masked appropriately. This needs to be verified.\\n\\n2. **Secrets Encryption**: \\n   - There is no information regarding the encryption of secrets at rest and in transit. This is crucial for security.\\n\\n3. **Data Encryption**: \\n   - Similar to secrets, there is no mention of data encryption at rest and in transit.\\n\\n4. **Base Image Usage**: \\n   - The pull request does not provide information about the base image used (distroless/mariner). This is important for security compliance.\\n\\n### Observability and Security Risk Report\\n\\n#### Observability Risks\\n- **Lack of Actionable Alerts**: The absence of alerts and runbooks for the new error handling can lead to delayed responses to issues.\\n- **No Metrics for Monitoring**: Without metrics, it will be difficult to monitor the health of the system and detect issues early.\\n- **Missing Correlation IDs**: The lack of Correlation IDs in logs can complicate troubleshooting and error tracing.\\n- **No Support for Dynamic Log Levels**: This limits the ability to troubleshoot effectively in production environments.\\n\\n#### Security Risks\\n- **Sensitive Data Exposure**: If sensitive log lines are not masked, there is a risk of exposing sensitive information.\\n- **Unverified Encryption Practices**: Without confirmation of encryption for secrets and data, there is a risk of data breaches.\\n- **Base Image Security**: The choice of base image is critical for security; without this information, potential vulnerabilities may exist.\\n\\n### Recommendations\\n1. **Implement Actionable Alerts**: Define alerts for the new error conditions and create runbooks for handling them.\\n2. **Add Monitoring Metrics**: Introduce metrics to monitor job statuses and error occurrences to facilitate quicker detection of issues.\\n3. **Establish Correlation IDs**: Implement Correlation IDs in logs to improve traceability of errors across components.\\n4. **Support Dynamic Log Levels**: Allow for changing log levels to aid in troubleshooting.\\n5. **Review Sensitive Log Handling**: Ensure that sensitive information is masked in logs.\\n6. **Verify Encryption Practices**: Confirm that all secrets and data are encrypted at rest and in transit.\\n7. **Assess Base Image Security**: Review and confirm the use of secure base images.\\n\\nThis analysis highlights the need for improvements in both observability and security in the changes introduced by the pull request.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [fetchprdiff,\n",
    "        file_fetch_tool,\n",
    "        prometheus_metrics_fetch_tool,\n",
    "        bandit_security_checker_tool]\n",
    "\n",
    "# repo_name=REPO_NAME\n",
    "# pr_number={PULL_REQUEST_NUMBER}\n",
    "# github_token={config.GITHUB_TOKEN} \n",
    "\n",
    "# human_message = f\"Analyze the {PULL_REQUEST_NUMBER} from {REPO_NAME}, Use {PULL_REQUEST_NUMBER} as pr_number and as {config.GITHUB_TOKEN} github_token\"\n",
    "\n",
    "# Instantiate the agent\n",
    "agent_instance = PRRAgent(config.llm, [fetchprdiff], prompt)\n",
    "\n",
    "# Prepare the input messages\n",
    "human_message = f\"Analyze the pull request {PULL_REQUEST_NUMBER} from {REPO_NAME}\"\n",
    "# human_message = f\"How are you doing?\"\n",
    "messages = [HumanMessage(content=human_message)]\n",
    "\n",
    "# Invoke the agent's graph and get the result\n",
    "result = agent_instance.graph.invoke({\"messages\": messages})\n",
    "\n",
    "# Display the agent's response\n",
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23378c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Analyze the pull request 1853 from greenqloud/cloud-backup-service', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
