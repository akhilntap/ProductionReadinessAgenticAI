{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be20361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import initialize_agent, Tool\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "import operator\n",
    "# from langchain.prompts import PromptTemplate\n",
    "import requests\n",
    "from github import Github\n",
    "import os\n",
    "import getpass\n",
    "from bandit.core import manager, config\n",
    "from azure.identity import ManagedIdentityCredential\n",
    "import config\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db4e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Config ===\n",
    "REPO_NAME = \"greenqloud/cloud-backup-service\"\n",
    "PULL_REQUEST_NUMBER = 1853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de03bfe5-67bc-44a6-84c8-225b5cfd0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prometheus_rule_groups(subscription_id, resource_group=config.RESOURCEGROUP, client_id=config.PROMETHEUS_CLIENT_ID):\n",
    "#     \"\"\"\n",
    "#     Fetch Prometheus rule groups from Azure Monitor and return as a DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         subscription_id (str): Azure subscription ID.\n",
    "#         resource_group (str): Azure resource group name.\n",
    "#         api_version (str): API version to use.\n",
    "#         client_id (str): Client ID for Managed Identity.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame containing rule group details, or None if the request fails.\n",
    "#     \"\"\"\n",
    "#     # Get token using Managed Identity (DefaultAzureCredential)\n",
    "#     credential = ManagedIdentityCredential(client_id=client_id)\n",
    "#     token = credential.get_token(\"https://management.azure.com/.default\").token\n",
    "\n",
    "#     # Construct API URL for listing all rule groups\n",
    "#     url = (\n",
    "#         f\"https://management.azure.com/subscriptions/{subscription_id}\"\n",
    "#         f\"/resourceGroups/{resource_group}/providers/Microsoft.AlertsManagement\"\n",
    "#         f\"/prometheusRuleGroups?api-version=2023-03-01\"\n",
    "#     )\n",
    "\n",
    "#     # Set headers with the bearer token\n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {token}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "\n",
    "#     # Make the GET request to Azure Monitor\n",
    "#     response = requests.get(url, headers=headers)\n",
    "\n",
    "#     # Check and process response\n",
    "#     if response.status_code == 200:\n",
    "#         data = response.json()\n",
    "#         rule_groups = []\n",
    "#         for rule_group in data.get(\"value\", []):\n",
    "#             rule_groups.append({\n",
    "#                 \"Name\": rule_group['name'],\n",
    "#                 \"Location\": rule_group.get('location'),\n",
    "#                 \"Description\": rule_group.get('properties', {}).get('description'),\n",
    "#                 \"Rules\": rule_group.get('properties', {}).get('rules')\n",
    "#             })\n",
    "#         return pd.DataFrame(rule_groups)\n",
    "#     else:\n",
    "#         print(f\"Failed to fetch rule groups. Status Code: {response.status_code}\")\n",
    "#         print(response.text)\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f4cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tool 1: GitHub PR Fetcher ===\n",
    "def fetch_pr_diff_and_metadata(repo_name=REPO_NAME, pr_number=PULL_REQUEST_NUMBER, github_token=config.GITHUB_TOKEN):\n",
    "    \"\"\"\n",
    "    Fetch pull request metadata and diff from GitHub.\n",
    "\n",
    "    Args:\n",
    "        repo_name (str): The full repository name (e.g., \"owner/repo\").\n",
    "        pr_number (int): The pull request number.\n",
    "        github_token (str): GitHub personal access token.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'pr', 'pr_title', 'pr_body', 'diff_text'.\n",
    "    \"\"\"\n",
    "    g = Github(github_token)\n",
    "    repo = g.get_repo(repo_name)\n",
    "    pr = repo.get_pull(pr_number)\n",
    "    pr_title = pr.title\n",
    "    pr_body = pr.body\n",
    "    diff_response = requests.get(\n",
    "        f\"https://api.github.com/repos/{repo_name}/pulls/{pr_number}\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"token {github_token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3.diff\"\n",
    "        }\n",
    "    )\n",
    "    diff_text = diff_response.text\n",
    "    return diff_text\n",
    "class prrepo(BaseModel):\n",
    "    repo_name: str = Field(description=\"Repo to execute\")\n",
    "    pr_number: int = Field(description=\"PR number to execute\")\n",
    "@tool(args_schema = prrepo)\n",
    "def fetchprdiff(repo_name: str, pr_number: int) -> str:\n",
    "  \"\"\"Returns the result of diff text in a PR\"\"\"\n",
    "  return fetch_pr_diff_and_metadata(repo_name, pr_number, github_token=config.GITHUB_TOKEN)\n",
    "\n",
    "\n",
    "# === Tool 1: GitHub File Fetcher ===\n",
    "def get_file_context(filename, ref=\"master\"):\n",
    "    g = Github(config.GITHUB_TOKEN)\n",
    "    repo = g.get_repo(REPO_NAME)\n",
    "    try:\n",
    "        contents = repo.get_contents(filename, ref=ref)\n",
    "        return contents.decoded_content.decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching file {filename}: {e}\"\n",
    "# Tool for langrgaph\n",
    "\n",
    "class filecontent(BaseModel):\n",
    "    filename: str = Field(description=\"Get full contents of file\")\n",
    "@tool(args_schema = filecontent)\n",
    "def file_fetch_tool(filename: str, ref: str = \"master\") -> str:\n",
    "   \"\"\"\n",
    "    Fetch full content of a given file from the repo for additional context.\n",
    "    \"\"\"\n",
    "   return get_file_context(filename, ref=\"master\")\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 2: Prometheus metrics fetcher ===\n",
    "def get_prometheus_metrics(prometheus_url=\"https://prometheusmdmeastus-stage-060d.eastus.prometheus.monitor.azure.com\"):\n",
    "    try:\n",
    "        credential = ManagedIdentityCredential(client_id=config.PROMETHEUS_CLIENT_ID)\n",
    "        token = credential.get_token(\"https://data.monitor.azure.com\").token\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\"\n",
    "        }\n",
    "        response = requests.get(f\"{prometheus_url}/api/v1/label/__name__/values\", headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data.get('status') == 'success':\n",
    "            return data.get('data', [])\n",
    "        else:\n",
    "            print(f\"Error from Prometheus API: {data}\")\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP request failed: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "# Tool for LangGraph\n",
    "class prometheusmetricsurl(BaseModel):\n",
    "    prometheus_url: str = Field(description=\"Get full contents of file\")\n",
    "@tool(args_schema = prometheusmetricsurl)\n",
    "def prometheus_metrics_fetch_tool(prometheus_url: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all the prometheus metrics from azure monitor workspace to get context for observability.\n",
    "    \"\"\"\n",
    "    return get_prometheus_metrics(prometheus_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 3: Prometheus alerts rule groups fetcher ===\n",
    "def get_prometheus_rule_groups(subscription_id, resource_group=config.RESOURCEGROUP, client_id=config.PROMETHEUS_CLIENT_ID):\n",
    "    \"\"\"\n",
    "    Fetch Prometheus rule groups from Azure Monitor and return as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        subscription_id (str): Azure subscription ID.\n",
    "        resource_group (str): Azure resource group name.\n",
    "        api_version (str): API version to use.\n",
    "        client_id (str): Client ID for Managed Identity.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing rule group details, or None if the request fails.\n",
    "    \"\"\"\n",
    "    # Get token using Managed Identity (DefaultAzureCredential)\n",
    "    credential = ManagedIdentityCredential(client_id=client_id)\n",
    "    token = credential.get_token(\"https://management.azure.com/.default\").token\n",
    "\n",
    "    # Construct API URL for listing all rule groups\n",
    "    url = (\n",
    "        f\"https://management.azure.com/subscriptions/{subscription_id}\"\n",
    "        f\"/resourceGroups/{resource_group}/providers/Microsoft.AlertsManagement\"\n",
    "        f\"/prometheusRuleGroups?api-version=2023-03-01\"\n",
    "    )\n",
    "\n",
    "    # Set headers with the bearer token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the GET request to Azure Monitor\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check and process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        rule_groups = []\n",
    "        for rule_group in data.get(\"value\", []):\n",
    "            rule_groups.append({\n",
    "                \"Name\": rule_group['name'],\n",
    "                \"Location\": rule_group.get('location'),\n",
    "                \"Description\": rule_group.get('properties', {}).get('description'),\n",
    "                \"Rules\": rule_group.get('properties', {}).get('rules')\n",
    "            })\n",
    "        return pd.DataFrame(rule_groups)\n",
    "    else:\n",
    "        print(f\"Failed to fetch rule groups. Status Code: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "# Tool for LangGraph\n",
    "class prometheusmetricsurla(BaseModel):\n",
    "    subscription_id: str = Field(description=\"subscription id\")\n",
    "@tool(args_schema = prometheusmetricsurla)\n",
    "def prometheus_alert_rule_group_fetch_tool(subscription_id: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all the prometheus metrics from azure monitor workspace to get context for observability.\n",
    "    \"\"\"\n",
    "    return get_prometheus_rule_groups(subscription_id)\n",
    "\n",
    "# # === Tool 4: Bandit Code Security checker ===\n",
    "# def check_code_security(file_path):\n",
    "#     \"\"\"\n",
    "#     Check a Python file for security vulnerabilities using Bandit.\n",
    "\n",
    "#     :param file_path: Path to the Python file to analyze\n",
    "#     :return: Bandit report as a string\n",
    "#     \"\"\"\n",
    "#     # Load Bandit configuration\n",
    "#     bandit_config = config.BanditConfig()\n",
    "\n",
    "#     # Initialize Bandit manager\n",
    "#     bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "\n",
    "#     # Run Bandit on the specified file\n",
    "#     bandit_manager.discover_files([file_path])\n",
    "#     bandit_manager.run_tests()\n",
    "\n",
    "#     # Generate and return the report\n",
    "#     issues = bandit_manager.get_issue_list()\n",
    "#     if not issues:\n",
    "#         return \"No high-level vulnerabilities found. Checking for lower-level issues...\"\n",
    "\n",
    "#     # If no high-level issues, check for lower-level issues\n",
    "#     lower_level_issues = []\n",
    "#     for issue in issues:\n",
    "#         if issue.severity.lower() in ['low', 'medium']:\n",
    "#             lower_level_issues.append(str(issue))\n",
    "\n",
    "#     if lower_level_issues:\n",
    "#         return \"\\n\".join(lower_level_issues)\n",
    "#     else:\n",
    "#         return \"No vulnerabilities found, including lower-level issues.\"\n",
    "# # Tool wrapper for LangChain\n",
    "# class banditsecurity(BaseModel):\n",
    "#     file_path: str = Field(description=\"Get path of file to execute\")\n",
    "# @tool(args_schema = banditsecurity)\n",
    "# def bandit_security_checker_tool(file_path: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Check security of a python code using bandit library.\n",
    "#     \"\"\"\n",
    "#     return check_code_security(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# === Tool 4: Bandit Code Security checker for PR files ===\n",
    "def check_pr_files_security(repo_name, pr_number):\n",
    "    \"\"\"\n",
    "    Fetch changed files in a PR, get their content, and check for security vulnerabilities using Bandit.\n",
    "\n",
    "    :param repo_name: Repository name (e.g., \"owner/repo\")\n",
    "    :param pr_number: Pull request number\n",
    "    :return: Bandit report as a string\n",
    "    \"\"\"\n",
    "    g = Github(config.GITHUB_TOKEN)\n",
    "    repo = g.get_repo(repo_name)\n",
    "    pr = repo.get_pull(pr_number)\n",
    "    changed_files = [f.filename for f in pr.get_files() if f.filename.endswith('.py')]\n",
    "    if not changed_files:\n",
    "        return \"No Python files changed in this PR.\"\n",
    "\n",
    "    results = []\n",
    "    for filename in changed_files:\n",
    "        code = get_file_context(filename, ref=pr.head.ref)\n",
    "        # Write code to a temporary file for Bandit to scan\n",
    "        with tempfile.NamedTemporaryFile(mode='w+', suffix='.py', delete=False) as tmp:\n",
    "            tmp.write(code)\n",
    "            tmp_path = tmp.name\n",
    "        # Run Bandit\n",
    "        bandit_config = config.BanditConfig()\n",
    "        bandit_manager = manager.BanditManager(bandit_config, \"file\", False)\n",
    "        bandit_manager.discover_files([tmp_path])\n",
    "        bandit_manager.run_tests()\n",
    "        issues = bandit_manager.get_issue_list()\n",
    "        if not issues:\n",
    "            results.append(f\"{filename}: No high-level vulnerabilities found.\")\n",
    "        else:\n",
    "            lower_level_issues = []\n",
    "            for issue in issues:\n",
    "                if issue.severity.lower() in ['low', 'medium']:\n",
    "                    lower_level_issues.append(str(issue))\n",
    "            if lower_level_issues:\n",
    "                results.append(f\"{filename}:\\n\" + \"\\n\".join(lower_level_issues))\n",
    "            else:\n",
    "                results.append(f\"{filename}: No vulnerabilities found, including lower-level issues.\")\n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "class banditprsecurity(BaseModel):\n",
    "    repo_name: str = Field(description=\"Repo to execute\")\n",
    "    pr_number: int = Field(description=\"PR number to execute\")\n",
    "@tool(args_schema = banditprsecurity)\n",
    "def bandit_pr_security_checker_tool(repo_name: str, pr_number: int) -> str:\n",
    "    \"\"\"\n",
    "    Check security of all Python files changed in a PR using the bandit library.\n",
    "    \"\"\"\n",
    "    return check_pr_files_security(repo_name, pr_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380adeb9-2ac9-430d-95d8-d888e559ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 06:09:20 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'fetch_pr_diff_and_metadata',\n",
       "  'description': 'Fetch pull request metadata and diff from GitHub.\\n\\nArgs:\\n    repo_name (str): The full repository name (e.g., \"owner/repo\").\\n    pr_number (int): The pull request number.\\n    github_token (str): GitHub personal access token.\\n\\nReturns:\\n    dict: Dictionary with keys \\'pr\\', \\'pr_title\\', \\'pr_body\\', \\'diff_text\\'.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'repo_name': {'description': None, 'type': 'object'},\n",
       "    'pr_number': {'description': None, 'type': 'object'},\n",
       "    'github_token': {'description': None, 'type': 'object'},\n",
       "    'description': None},\n",
       "   'required': ['repo_name', 'pr_number', 'github_token']}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_router.utils.function_call import FunctionSchema\n",
    "# create the function calling schema for ollama\n",
    "execute_query_schema = FunctionSchema(fetch_pr_diff_and_metadata).to_ollama()\n",
    "# execute_query_schema[\"function\"][\"parameters\"][\"properties\"][\"description\"] = None\n",
    "execute_query_schema[\"function\"][\"parameters\"][\"properties\"][\"description\"] = None\n",
    "execute_query_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "206fa2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent state\n",
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e0cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRRAgent:\n",
    "  # initialising the object\n",
    "  def __init__(self, model, tools, system_prompt = \"\"):\n",
    "    self.system_prompt = system_prompt\n",
    "\n",
    "    # initialising graph with a state \n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    # adding nodes \n",
    "    graph.add_node(\"llm\", self.call_llm)\n",
    "    graph.add_node(\"function\", self.execute_function)\n",
    "    graph.add_conditional_edges(\n",
    "      \"llm\",\n",
    "      self.exists_function_calling,\n",
    "      {True: \"function\", False: END}\n",
    "    )\n",
    "    graph.add_edge(\"function\", \"llm\")\n",
    "\n",
    "    # setting starting point\n",
    "    graph.set_entry_point(\"llm\")\n",
    "\n",
    "    self.graph = graph.compile()\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "    self.model = model.bind_tools(tools)\n",
    "\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    try:\n",
    "      display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    except Exception:\n",
    "      # This requires some extra dependencies and is optional\n",
    "      pass\n",
    "\n",
    "  def call_llm(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    # adding system prompt if it's defined\n",
    "    if self.system_prompt:\n",
    "        messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "\n",
    "    # calling LLM\n",
    "    message = self.model.invoke(messages)\n",
    "\n",
    "    return {'messages': [message]}\n",
    "  \n",
    "  def execute_function(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    results = []\n",
    "    for tool in tool_calls:\n",
    "      # checking whether tool name is correct\n",
    "      if not tool['name'] in self.tools:\n",
    "        # returning error to the agent \n",
    "        result = \"Error: There's no such tool, please, try again\" \n",
    "      else:\n",
    "        # getting result from the tool\n",
    "        result = self.tools[tool['name']].invoke(tool['args'])\n",
    "\n",
    "      results.append(\n",
    "        ToolMessage(\n",
    "          tool_call_id=tool['id'], \n",
    "          name=tool['name'], \n",
    "          content=str(result)\n",
    "        )\n",
    "    )\n",
    "    return {'messages': results}\n",
    "  \n",
    "  def exists_function_calling(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9b9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a senior AI engineer agent. you would wear multiple hats in the fields of observability and security\n",
    "TASK:\n",
    "Analyze the given pull request diff for potential observability and security issues.\n",
    "Use fetchprdiff tool to fetch the diff on a pull request\n",
    "Use a checklist for each area:\n",
    "For observability:\n",
    "- Are there actionable alerts identified for the feature? Are there Runbooks for the actionable alerts? Do we have TSGs attached to the alert? use prometheus_alert_rule_group_fetch_tool to see if there are already alert rules related to this change\n",
    "- Are there metrics to monitor dependencies and exception handling on components, infrastructure and features so that SRE can create alerts to reduce TTD? Use prometheus_metrics_fetch_tool to see if there are metrics related to the change \n",
    "- Are there CorrelationIDs established in logs to derive error lineage across various components?\n",
    "- Can the feature/service support changing log levels for troubleshooting purposes?\n",
    "- Are there critical log lines that we need to get alerted upon?\n",
    "For Security \n",
    "- All sensitive log lines are masked appropriately?\n",
    "- Are all secrets encrypted at rest and in transit?\n",
    "- Are all data encrypted at rest and in transit?\n",
    "- Are we using distroless/mariner base image/s?\n",
    "If the diff is unclear, use the FileFetcher tool to retrieve extra context of the file.\n",
    "If the file has import from custom modules use the file_fetch_tool tool to retreive the file\n",
    "Tell me if you fetched files for additional context\n",
    "Begin step-by-step reasoning.\n",
    "First, summarize what the change is doing.\n",
    "Then, identify observability gaps and risky areas.\n",
    "Finally, provide a observability and security risk report.\n",
    "Structure your response in a markdown format and add a table with the following columns:\n",
    "| Area | Gap | Risk Level | Recommendation |\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61c74357-9549-42fe-ad40-969d0230e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "# qwen3:32b            e1c9f234c6eb    20 GB    About a minute ago very good\n",
    "# gemma3:27b           a418f5838eaf    17 GB    5 minutes ago doesn't support tools\n",
    "# qwen2.5-coder:32b    4bd6cbf2d094    19 GB    6 minutes ago\n",
    "# devstral:latest      c4b2fa0c33d7    14 GB    8 minutes ago\n",
    "# llama3.3:latest      a6eb4748fd29    42 GB    2 days ago not bad but often fails tool calling\n",
    "# granite-code:34b\n",
    "modelname =  \"llama3.3:latest\" \n",
    "model = ChatOllama(model=modelname, temperature=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "481d5a2f-90b0-41e4-acb7-71174cb00daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 06:17:24 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-05-28 06:17:51 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage: Analyze the pull request 1853 from greenqloud/cloud-backup-service\n",
      "\n",
      "ToolMessage: diff --git a/api_service/server/database/database.go b/api_service/server/database/database.go\n",
      "index bc34add74..145ec0ed3 100644\n",
      "--- a/api_service/server/database/database.go\n",
      "+++ b/api_service/server/database/database.go\n",
      "@@ -35,6 +35,7 @@ const (\n",
      " \tDEFAULTLIMIT               = 100\n",
      " \t// MariaDBInReadOnlyModeError Expected substring for error incurred due to maria db being in read-only mode\n",
      " \tMariaDBInReadOnlyModeError = \"Error 1290: The MariaDB server is running with the --read-only\"\n",
      "+\tGSProcessingError          = \"GS is processing baseline backup\"\n",
      " )\n",
      " \n",
      " // The '_' and '%' are wildcards in a LIKE operated statement in SQL.\n",
      "@@ -174,15 +175,16 @@ func (sqlDb *SqlDatabase) CreateJobIfNotInProgress(jobType, fileSystemID, json s\n",
      " \tLIMIT 1`\n",
      " \t*/\n",
      " \tjobExists := false\n",
      "-\tvar row int\n",
      "+\n",
      "+\tvar job_type, errMsg string\n",
      " \texclusiveJobTypes := fmt.Sprintf(\"'%s','%s'\", util.RestoreJobType, util.DeleteQuarkObjectStoreType)\n",
      " \t// avoid duplicate sync jobs\n",
      " \tif jobType != util.UpdateDBJobType {\n",
      " \t\texclusiveJobTypes += fmt.Sprintf(\",'%s'\", util.UpdateDBJobType)\n",
      " \t}\n",
      "-\tqueryFmt := `SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = ? AND type NOT IN (` + exclusiveJobTypes + `)  \n",
      "+\tqueryFmt := `SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = ? AND type NOT IN (` + exclusiveJobTypes + `)  \n",
      "                  AND (status = '` + util.NEWSTATUS + `' OR status = '` + util.INPROGRESSSTATUS + `') LIMIT 1`\n",
      "-\terr := sqlDb.sql.QueryRow(queryFmt, fileSystemID).Scan(&row)\n",
      "+\terr := sqlDb.sql.QueryRow(queryFmt, fileSystemID).Scan(&job_type, &errMsg)\n",
      " \tif err != nil {\n",
      " \t\tif err != sql.ErrNoRows {\n",
      " \t\t\tsqlDb.GetTraceLog().Errorf(\"CreateJobIfNotInProgress(jobType=%s, fileSystemID=%s) failed: %v\", jobType, fileSystemID, err)\n",
      "@@ -193,6 +195,11 @@ func (sqlDb *SqlDatabase) CreateJobIfNotInProgress(jobType, fileSystemID, json s\n",
      " \t\tjobExists = true\n",
      " \t}\n",
      " \n",
      "+\tif jobExists && job_type == util.ScheduledBackupWithPolicyJobType && errMsg == GSProcessingError {\n",
      "+\t\tsqlDb.GetTraceLog().Errorf(\"jobExists in CreateJobIfNotInProgress(jobType=%s, fileSystemID=%s)\", jobType, fileSystemID)\n",
      "+\t\terrorMessage := \"Baseline backup is in progress. Please retry once baseline backup creation is completed.\"\n",
      "+\t\treturn 0, util.NewDuplicateEntryError(errorMessage)\n",
      "+\t}\n",
      " \tif jobExists {\n",
      " \t\tsqlDb.GetTraceLog().Errorf(\"jobExists in CreateJobIfNotInProgress(jobType=%s, fileSystemID=%s)\", jobType, fileSystemID)\n",
      " \t\terrorMessage := \"Cannot create a new job as another job is in progress for the given fileSystemID.\"\n",
      "diff --git a/api_service/server/database/miscellaneous_test.go b/api_service/server/database/miscellaneous_test.go\n",
      "index d70a5c6ef..0743d77ec 100644\n",
      "--- a/api_service/server/database/miscellaneous_test.go\n",
      "+++ b/api_service/server/database/miscellaneous_test.go\n",
      "@@ -181,8 +181,9 @@ func Test_CreateJobIfNotInProgress_DuplicateEntry(t *testing.T) {\n",
      " \n",
      " \tdefer resetSQLMock()\n",
      " \n",
      "-\tsqlMock.ExpectQuery(`SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "-                 AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).WillReturnRows(sqlmock.NewRows([]string{\"i\"}).AddRow(1))\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "+                 AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).\n",
      "+\t\tWillReturnRows(sqlmock.NewRows([]string{\"type\", \"error_message\"}).AddRow(util.AdhocBackupJobType, \"IN_PROGRESS_ERROR\"))\n",
      " \n",
      " \t_, createErr := dbTest.CreateJobIfNotInProgress(jobType, fileSystemID, json)\n",
      " \tassert.Equal(t, createErr, util.NewDuplicateEntryError(\"Cannot create a new job as another job is in progress for the given fileSystemID.\"))\n",
      "@@ -229,7 +230,7 @@ func Test_CreateJobIfNotInProgress_NoRowsSuccess_JobSuccess(t *testing.T) {\n",
      " \n",
      " \tdefer resetSQLMock()\n",
      " \n",
      "-\tsqlMock.ExpectQuery(`SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "                  AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).WillReturnError(sql.ErrNoRows)\n",
      " \n",
      " \tsqlMock.ExpectQuery(`INSERT INTO JOB_STATUS \\(type, status, error_message, message, file_system_uuid\\) VALUES \\(\\?, \\?, \\?, \\?, \\?\\)`).\n",
      "@@ -247,7 +248,7 @@ func Test_CreateJobIfNotInProgress_WhenJobTypeIsUpdateDB(t *testing.T) {\n",
      " \n",
      " \tdefer resetSQLMock()\n",
      " \n",
      "-\tsqlMock.ExpectQuery(`SELECT 1 FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store'\\)\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store'\\)\n",
      "                  AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).WithArgs(fileSystemID).WillReturnError(sql.ErrNoRows)\n",
      " \n",
      " \tsqlMock.ExpectQuery(`INSERT INTO JOB_STATUS \\(type, status, error_message, message, file_system_uuid\\) VALUES \\(\\?, \\?, \\?, \\?, \\?\\)`).\n",
      "@@ -258,6 +259,27 @@ func Test_CreateJobIfNotInProgress_WhenJobTypeIsUpdateDB(t *testing.T) {\n",
      " \tassert.EqualValues(t, id, 1)\n",
      " }\n",
      " \n",
      "+func Test_CreateJobIfNotInProgress_WhenJobExists_GSProcessingError(t *testing.T) {\n",
      "+\tjobType := util.ScheduledBackupWithPolicyJobType\n",
      "+\tfileSystemID := \"622EE7E2-AFDD-536D-A337-012345678923\"\n",
      "+\tjson := \"random data\"\n",
      "+\n",
      "+\tdefer resetSQLMock()\n",
      "+\n",
      "+\trows := sqlmock.NewRows([]string{\"type\", \"error_message\"}).\n",
      "+\t\tAddRow(util.ScheduledBackupWithPolicyJobType, GSProcessingError)\n",
      "+\n",
      "+\tsqlMock.ExpectQuery(`SELECT type, error_message FROM JOB_STATUS WHERE file_system_uuid = \\? AND type NOT IN \\('restore','delete-quark-object-store','update-db'\\)\n",
      "+                 AND \\(status = 'NEW' OR status = 'INPROGRESS'\\) LIMIT 1`).\n",
      "+\t\tWithArgs(fileSystemID).\n",
      "+\t\tWillReturnRows(rows)\n",
      "+\n",
      "+\t_, createErr := dbTest.CreateJobIfNotInProgress(jobType, fileSystemID, json)\n",
      "+\n",
      "+\tassert.NotNil(t, createErr)\n",
      "+\tassert.Equal(t, \"Baseline backup is in progress. Please retry once baseline backup creation is completed.\", createErr.Error())\n",
      "+}\n",
      "+\n",
      " func Test_DeleteJob_NotFound(t *testing.T) {\n",
      " \tvar jobID uint64 = 1\n",
      " \n",
      "\n",
      "\n",
      "AIMessage: ## Summary of the Change\n",
      "The pull request 1853 from greenqloud/cloud-backup-service modifies the `CreateJobIfNotInProgress` function in the `database.go` file to handle a new error case when a baseline backup is in progress. The change adds a check for the `GSProcessingError` error message and returns a `DuplicateEntryError` with a specific error message if the job exists and the error message matches.\n",
      "\n",
      "## Observability Gaps and Risky Areas\n",
      "The following observability gaps and risky areas were identified:\n",
      "\n",
      "* There are no actionable alerts defined for the new error case introduced by this change.\n",
      "* There are no metrics to monitor dependencies and exception handling on components, infrastructure, and features related to this change.\n",
      "* CorrelationIDs are not established in logs to derive error lineage across various components.\n",
      "* The feature/service does not support changing log levels for troubleshooting purposes.\n",
      "* Critical log lines that require alerts are not defined.\n",
      "\n",
      "## Security Risks\n",
      "The following security risks were identified:\n",
      "\n",
      "* Sensitive log lines may not be masked appropriately.\n",
      "* Secrets may not be encrypted at rest and in transit.\n",
      "* Data may not be encrypted at rest and in transit.\n",
      "* The base image used may not be distroless/mariner, which could introduce security vulnerabilities.\n",
      "\n",
      "## Recommendations\n",
      "The following recommendations are made to address the observability gaps and security risks:\n",
      "\n",
      "| Area | Gap | Risk Level | Recommendation |\n",
      "| --- | --- | --- | --- |\n",
      "| Observability | No actionable alerts defined | High | Define actionable alerts for the new error case and ensure that runbooks and TSGs are attached to the alert. |\n",
      "| Observability | No metrics to monitor dependencies and exception handling | Medium | Implement metrics to monitor dependencies and exception handling on components, infrastructure, and features related to this change. |\n",
      "| Observability | CorrelationIDs not established in logs | Medium | Establish CorrelationIDs in logs to derive error lineage across various components. |\n",
      "| Observability | Feature/service does not support changing log levels for troubleshooting purposes | Low | Implement the ability to change log levels for troubleshooting purposes. |\n",
      "| Observability | Critical log lines not defined | Low | Define critical log lines that require alerts. |\n",
      "| Security | Sensitive log lines may not be masked appropriately | High | Ensure that sensitive log lines are masked appropriately. |\n",
      "| Security | Secrets may not be encrypted at rest and in transit | High | Ensure that secrets are encrypted at rest and in transit. |\n",
      "| Security | Data may not be encrypted at rest and in transit | High | Ensure that data is encrypted at rest and in transit. |\n",
      "| Security | Base image may not be distroless/mariner | Medium | Use a distroless/mariner base image to reduce security vulnerabilities. |\n",
      "\n",
      "No additional files were fetched for this analysis.\n",
      "\n",
      "To further analyze the change, the following tools can be used:\n",
      "\n",
      "* `prometheus_alert_rule_group_fetch_tool` to check if there are already alert rules related to this change.\n",
      "* `prometheus_metrics_fetch_tool` to check if there are metrics related to this change.\n",
      "* `FileFetcher` tool to retrieve extra context of the file.\n",
      "* `file_fetch_tool` tool to retrieve custom modules imported in the file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## Summary of the Change\\nThe pull request 1853 from greenqloud/cloud-backup-service modifies the `CreateJobIfNotInProgress` function in the `database.go` file to handle a new error case when a baseline backup is in progress. The change adds a check for the `GSProcessingError` error message and returns a `DuplicateEntryError` with a specific error message if the job exists and the error message matches.\\n\\n## Observability Gaps and Risky Areas\\nThe following observability gaps and risky areas were identified:\\n\\n* There are no actionable alerts defined for the new error case introduced by this change.\\n* There are no metrics to monitor dependencies and exception handling on components, infrastructure, and features related to this change.\\n* CorrelationIDs are not established in logs to derive error lineage across various components.\\n* The feature/service does not support changing log levels for troubleshooting purposes.\\n* Critical log lines that require alerts are not defined.\\n\\n## Security Risks\\nThe following security risks were identified:\\n\\n* Sensitive log lines may not be masked appropriately.\\n* Secrets may not be encrypted at rest and in transit.\\n* Data may not be encrypted at rest and in transit.\\n* The base image used may not be distroless/mariner, which could introduce security vulnerabilities.\\n\\n## Recommendations\\nThe following recommendations are made to address the observability gaps and security risks:\\n\\n| Area | Gap | Risk Level | Recommendation |\\n| --- | --- | --- | --- |\\n| Observability | No actionable alerts defined | High | Define actionable alerts for the new error case and ensure that runbooks and TSGs are attached to the alert. |\\n| Observability | No metrics to monitor dependencies and exception handling | Medium | Implement metrics to monitor dependencies and exception handling on components, infrastructure, and features related to this change. |\\n| Observability | CorrelationIDs not established in logs | Medium | Establish CorrelationIDs in logs to derive error lineage across various components. |\\n| Observability | Feature/service does not support changing log levels for troubleshooting purposes | Low | Implement the ability to change log levels for troubleshooting purposes. |\\n| Observability | Critical log lines not defined | Low | Define critical log lines that require alerts. |\\n| Security | Sensitive log lines may not be masked appropriately | High | Ensure that sensitive log lines are masked appropriately. |\\n| Security | Secrets may not be encrypted at rest and in transit | High | Ensure that secrets are encrypted at rest and in transit. |\\n| Security | Data may not be encrypted at rest and in transit | High | Ensure that data is encrypted at rest and in transit. |\\n| Security | Base image may not be distroless/mariner | Medium | Use a distroless/mariner base image to reduce security vulnerabilities. |\\n\\nNo additional files were fetched for this analysis.\\n\\nTo further analyze the change, the following tools can be used:\\n\\n* `prometheus_alert_rule_group_fetch_tool` to check if there are already alert rules related to this change.\\n* `prometheus_metrics_fetch_tool` to check if there are metrics related to this change.\\n* `FileFetcher` tool to retrieve extra context of the file.\\n* `file_fetch_tool` tool to retrieve custom modules imported in the file.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [fetchprdiff,\n",
    "        file_fetch_tool,\n",
    "        prometheus_metrics_fetch_tool,\n",
    "        prometheus_alert_rule_group_fetch_tool,\n",
    "        bandit_pr_security_checker_tool\n",
    "        ]\n",
    "# Instantiate the agent\n",
    "agent_instance = PRRAgent(model, tools, prompt)\n",
    "\n",
    "# Prepare the input messages\n",
    "human_message = f\"Analyze the pull request {PULL_REQUEST_NUMBER} from {REPO_NAME}\"\n",
    "messages = [HumanMessage(content=human_message)]\n",
    "\n",
    "# Invoke the agent's graph and get the result\n",
    "result = agent_instance.graph.invoke({\"messages\": messages})\n",
    "\n",
    "# Print the agent's thought process and tool usage\n",
    "for msg in result['messages']:\n",
    "    if hasattr(msg, 'content') and msg.content:\n",
    "        print(f\"{msg.__class__.__name__}: {msg.content}\\n\")\n",
    "\n",
    "# Display the agent's response\n",
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e4b0723-0063-4cd0-88e4-2859838a7e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Summary of the Change\\nThe pull request 1853 from greenqloud/cloud-backup-service modifies the `CreateJobIfNotInProgress` function in the `database.go` file to handle a new error case when a baseline backup is in progress. The change adds a check for the `GSProcessingError` error message and returns a `DuplicateEntryError` with a specific error message if the job exists and the error message matches.\\n\\n## Observability Gaps and Risky Areas\\nThe following observability gaps and risky areas were identified:\\n\\n* There are no actionable alerts defined for the new error case introduced by this change.\\n* There are no metrics to monitor dependencies and exception handling on components, infrastructure, and features related to this change.\\n* CorrelationIDs are not established in logs to derive error lineage across various components.\\n* The feature/service does not support changing log levels for troubleshooting purposes.\\n* Critical log lines that require alerts are not defined.\\n\\n## Security Risks\\nThe following security risks were identified:\\n\\n* Sensitive log lines may not be masked appropriately.\\n* Secrets may not be encrypted at rest and in transit.\\n* Data may not be encrypted at rest and in transit.\\n* The base image used may not be distroless/mariner, which could introduce security vulnerabilities.\\n\\n## Recommendations\\nThe following recommendations are made to address the observability gaps and security risks:\\n\\n| Area | Gap | Risk Level | Recommendation |\\n| --- | --- | --- | --- |\\n| Observability | No actionable alerts defined | High | Define actionable alerts for the new error case and ensure that runbooks and TSGs are attached to the alert. |\\n| Observability | No metrics to monitor dependencies and exception handling | Medium | Implement metrics to monitor dependencies and exception handling on components, infrastructure, and features related to this change. |\\n| Observability | CorrelationIDs not established in logs | Medium | Establish CorrelationIDs in logs to derive error lineage across various components. |\\n| Observability | Feature/service does not support changing log levels for troubleshooting purposes | Low | Implement the ability to change log levels for troubleshooting purposes. |\\n| Observability | Critical log lines not defined | Low | Define critical log lines that require alerts. |\\n| Security | Sensitive log lines may not be masked appropriately | High | Ensure that sensitive log lines are masked appropriately. |\\n| Security | Secrets may not be encrypted at rest and in transit | High | Ensure that secrets are encrypted at rest and in transit. |\\n| Security | Data may not be encrypted at rest and in transit | High | Ensure that data is encrypted at rest and in transit. |\\n| Security | Base image may not be distroless/mariner | Medium | Use a distroless/mariner base image to reduce security vulnerabilities. |\\n\\nNo additional files were fetched for this analysis.\\n\\nTo further analyze the change, the following tools can be used:\\n\\n* `prometheus_alert_rule_group_fetch_tool` to check if there are already alert rules related to this change.\\n* `prometheus_metrics_fetch_tool` to check if there are metrics related to this change.\\n* `FileFetcher` tool to retrieve extra context of the file.\\n* `file_fetch_tool` tool to retrieve custom modules imported in the file.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the agent's response\n",
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "349e5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize the compiled agent graph\n",
    "display(Image(agent_instance.graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac26b0a-499b-4f0f-aa44-aa7254a044a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
